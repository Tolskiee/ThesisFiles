{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akin', 'aking', 'ako', 'alin', 'am', 'amin', 'aming', 'ang', 'ano', 'anumang', 'apat', 'at', 'atin', 'ating', 'ay', 'bababa', 'bago', 'bakit', 'bawat', 'bilang', 'dahil', 'dalawa', 'dapat', 'din', 'dito', 'doon', 'gagawin', 'gayunman', 'ginagawa', 'ginawa', 'ginawang', 'gumawa', 'gusto', 'habang', 'hanggang', 'hindi', 'huwag', 'iba', 'ibaba', 'ibabaw', 'ibig', 'ikaw', 'ilagay', 'ilalim', 'ilan', 'inyong', 'isa', 'isang', 'itaas', 'ito', 'iyo', 'iyon', 'iyong', 'ka', 'kahit', 'kailangan', 'kailanman', 'kami', 'kanila', 'kanilang', 'kanino', 'kanya', 'kanyang', 'kapag', 'kapwa', 'karamihan', 'katiyakan', 'katulad', 'kaya', 'kaysa', 'ko', 'kong', 'kulang', 'kumuha', 'kung', 'laban', 'lahat', 'lamang', 'likod', 'lima', 'maaari', 'maaaring', 'maging', 'mahusay', 'makita', 'marami', 'marapat', 'masyado', 'may', 'mayroon', 'mga', 'minsan', 'mismo', 'mula', 'muli', 'na', 'nabanggit', 'naging', 'nagkaroon', 'nais', 'nakita', 'namin', 'napaka', 'narito', 'nasaan', 'ng', 'ngayon', 'ni', 'nila', 'nilang', 'nito', 'niya', 'niyang', 'noon', 'o', 'pa', 'paano', 'pababa', 'paggawa', 'pagitan', 'pagkakaroon', 'pagkatapos', 'palabas', 'pamamagitan', 'panahon', 'pangalawa', 'para', 'paraan', 'pareho', 'pataas', 'pero', 'pumunta', 'pumupunta', 'sa', 'saan', 'sabi', 'sabihin', 'sarili', 'sila', 'sino', 'siya', 'tatlo', 'tayo', 'tulad', 'tungkol', 'una', 'walang']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import urllib.request, json \n",
    "\n",
    "def clean_tweets(df):\n",
    "    tempArr = []\n",
    "    for line in df:\n",
    "        # send to tweet_processor\n",
    "        tmpL = p.clean(line)\n",
    "        # remove everything except letters and digits\n",
    "        tmpL = re.sub(r'[^a-zA-Z0-9\\s]', ' ', tmpL)\n",
    "        # convert to lowercase\n",
    "        tmpL = tmpL.lower()\n",
    "        tempArr.append(tmpL)\n",
    "    return tempArr\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\d)|(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")\n",
    "\n",
    "train = pd.read_csv(r\"C:\\Users\\jmest\\Documents\\Files\\C4S2\\Thesis\\ThesisFiles-main\\ThesisFiles-main\\hatespeech\\train.csv\", nrows=5000)\n",
    "\n",
    "\n",
    "train_tweet = clean_tweets(train[\"text\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)\n",
    "train[\"clean_tweet\"] = train_tweet\n",
    "sum(train['clean_tweet'] == '')\n",
    "train['clean_tweet'] = train['clean_tweet'].replace('', np.NaN)\n",
    "train['clean_tweet'] = train['clean_tweet'].replace('', float('NaN'), regex = True)\n",
    "train.dropna(inplace= True)\n",
    "train = train.reset_index(drop=True)\n",
    "first_column = train.pop('label')\n",
    "train.insert(0,'label',first_column)\n",
    "train.dropna(axis='rows')\n",
    "\n",
    "with urllib.request.urlopen(\"https://raw.githubusercontent.com/stopwords-iso/stopwords-tl/master/stopwords-tl.json\") as url:\n",
    "    stopwords = json.loads(url.read().decode())\n",
    "    print(stopwords)\n",
    "\n",
    "\n",
    "train['rm_stpwrds'] = train['clean_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords) and not word.isdigit()]))\n",
    "train['tokenize'] = train['rm_stpwrds'].apply(nltk.tokenize.WhitespaceTokenizer().tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rm_stpwrds</th>\n",
       "      <th>tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rm_stpwrds tokenize\n",
       "0                  []\n",
       "1                  []\n",
       "2                  []\n",
       "3                  []\n",
       "4                  []\n",
       "5                  []\n",
       "6                  []\n",
       "7                  []\n",
       "8                  []\n",
       "9                  []"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['rm_stpwrds','tokenize']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4735, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOWELS = \"aeiouAEIOU\"\n",
    "CONSONANTS = \"bcdfghklmnngpqrstvwyBCDFGHKLMNNGPQRSTVWY\"\n",
    "\n",
    "\"\"\" \n",
    "\tAffixes\n",
    "\"\"\"\n",
    "PREFIX_SET = [\n",
    "\t'nakikipag', 'pakikipag',\n",
    "\t'pinakama', 'pagpapa',\n",
    "\t'pinagka', 'panganga', \n",
    "\t'makapag', 'nakapag', \n",
    "\t'tagapag', 'makipag', \n",
    "\t'nakipag', 'tigapag',\n",
    "\t'pakiki', 'magpa',\n",
    "\t'napaka', 'pinaka',\n",
    "\t'ipinag', 'pagka', \n",
    "\t'pinag', 'mapag', \n",
    "\t'mapa', 'taga', \n",
    "\t'ipag', 'tiga', \n",
    "\t'pala', 'pina', \n",
    "\t'pang', 'naka',\n",
    "\t'nang', 'mang',\n",
    "\t'sing',\n",
    "\t'ipa', 'pam',\n",
    "\t'pan', 'pag',\n",
    "\t'tag', 'mai',\n",
    "\t'mag', 'nam',\n",
    "\t'nag', 'man',\n",
    "\t'may', 'ma',\n",
    "\t'na', 'ni',\n",
    "\t'pa', 'ka',\n",
    "\t'um', 'in',\n",
    "\t'i',\n",
    "]\n",
    "\n",
    "INFIX_SET = [\n",
    "\t'um', 'in',\n",
    "]\n",
    "\n",
    "SUFFIX_SET = [\n",
    "\t'syon','dor', \n",
    "\t'ita', 'han', \n",
    "\t'hin', 'ing', \n",
    "\t'ang', 'ng', \n",
    "\t'an', 'in', \n",
    "\t'g',\n",
    "]\n",
    "\n",
    "PERIOD_FLAG = True\n",
    "PASS_FLAG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_vowel(substring):\n",
    "\t\"\"\"\n",
    "\t\tChecks if the substring is a vowel.\n",
    "\t\t\tletters: substring to be tested\n",
    "\t\treturns BOOLEAN\n",
    "\t\"\"\"\n",
    "\n",
    "\treturn all(letter in VOWELS for letter in substring)\n",
    "\n",
    "\n",
    "def check_consonant(substring):\n",
    "\t\"\"\"\n",
    "\t\tChecks if the letter is a consonant.\n",
    "\t\t\tletter: substring to be tested\n",
    "\t\treturns BOOLEAN\n",
    "\t\"\"\"\n",
    "\n",
    "\treturn all(letter in CONSONANTS for letter in substring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_letter(token, index, letter):\n",
    "\t\"\"\"\n",
    "\t\tReplaces a letter in a token.\n",
    "\t\t\ttoken: word to be used\n",
    "\t\t\tindex: index of the letter\n",
    "\t\t\tletter: letter used to replace\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t_list = list(token)\n",
    "\t_list[index] = letter\n",
    "\n",
    "\treturn ''.join(_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vowel(token):\n",
    "\t\"\"\"\n",
    "\t\tCount vowels in a given token.\n",
    "\t\t\ttoken: string to be counted for vowels\n",
    "\t\treturns INTEGER\n",
    "\t\"\"\"\n",
    "\n",
    "\tcount = 0\n",
    "\n",
    "\tfor tok in token:\n",
    "\t\tif check_vowel(tok):\n",
    "\t\t\tcount+=1\n",
    "\n",
    "\treturn count\n",
    "\n",
    "\n",
    "def count_consonant(token):\n",
    "\t\"\"\"\n",
    "\t\tCount consonants in a given token.\n",
    "\t\t\ttoken: string to be counted for consonants\n",
    "\t\treturns INTEGER\n",
    "\t\"\"\"\n",
    "\n",
    "\tcount = 0\n",
    "\n",
    "\tfor tok in token:\n",
    "\t\tif check_consonant(tok):\n",
    "\t\t\tcount+=1\n",
    "\n",
    "\treturn count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validation(token):\n",
    "    with open('validation.txt', 'r') as valid:\n",
    "        data = valid.read().replace('\\n', ' ').split(' ')\n",
    "\n",
    "    return token in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_repitition(token, REPITITION):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for repitition. (ex. nakakabaliw = nabaliw)\n",
    "\t\t\ttoken: word to be stemmed repitition\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tif len(token) >= 4:\n",
    "\t\tif check_vowel(token[0]):\n",
    "\t\t\tif token[0] == token[1]:\n",
    "\t\t\t\tREPITITION.append(token[0])\n",
    "\t\t\t\treturn token[1:]\n",
    "\n",
    "\t\telif check_consonant(token[0]) and count_vowel(token) >= 2:\n",
    "\t\t\tif token[0: 2] == token[2: 4] and len(token) - 2 >= 4:\n",
    "\t\t\t\tREPITITION.append(token[2:4])\n",
    "\t\t\t\treturn token[2:]\n",
    "\t\t\t\n",
    "\t\t\telif token[0: 3] == token[3: 6] and len(token) - 3 >= 4:\n",
    "\t\t\t\tREPITITION.append(token[3:6])\n",
    "\t\t\t\treturn token[3:]\n",
    "\n",
    "\treturn token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_suffix(token, SUFFIX):\n",
    "    \"\"\"\n",
    "    Checks token for suffixes. (ex. bigayan = bigay)\n",
    "        token: word to be stemmed for suffixes\n",
    "    returns STRING\n",
    "    \"\"\"\n",
    "\n",
    "    SUF_CANDIDATE = []\n",
    "\n",
    "    if check_validation(token):\n",
    "        return token\n",
    "\n",
    "    for suffix in SUFFIX_SET:\n",
    "        if len(token) - len(suffix) >= 3 and count_vowel(token[0:len(token) - len(suffix)]) >= 2 and count_consonant(token[0:len(token) - len(suffix)]) >= 1:\n",
    "            if token[len(token) - len(suffix): len(token)] == suffix:\n",
    "                if len(suffix) == 2 and not count_consonant(token[0:len(token) - len(suffix)]) >= 1:\n",
    "                    continue\n",
    "\n",
    "                if count_vowel(token[0: len(token) - len(suffix)]) >= 2:\n",
    "                    if suffix == 'ang' and check_consonant(token[-4]) \\\n",
    "                            and token[-4] != 'r' and token[-5] != 'u':\n",
    "                        continue\n",
    "\n",
    "                    print(token[0: len(token) - len(suffix)] + \" : \" + suffix)\n",
    "\n",
    "                    if check_validation(token[0: len(token) - len(suffix)]):\n",
    "                        SUFFIX.append(suffix)\n",
    "                        return token[0: len(token) - len(suffix)] + 'a' if suffix == 'ita' \\\n",
    "                            else token[0: len(token) - len(suffix)]\n",
    "\n",
    "                    elif len(SUF_CANDIDATE) == 0:\n",
    "                        SUF_CANDIDATE.append(suffix)\n",
    "                        SUF_CANDIDATE.append(token[0: len(token) - len(suffix)])\n",
    "\n",
    "    if (len(SUF_CANDIDATE) == 2):\n",
    "        SUFFIX = SUF_CANDIDATE[0]\n",
    "        return SUF_CANDIDATE[1][0: len(token) - len(SUFFIX)] + 'a' if SUFFIX == 'ita' \\\n",
    "            else SUF_CANDIDATE[1][0: len(token) - len(SUFFIX)]\n",
    "\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_infix(token, INFIX):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for infixes. (ex. bumalik = balik)\n",
    "\t\t\ttoken: word to be stemmed for infixes\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tfor infix in INFIX_SET:\n",
    "\t\tif len(token) - len(infix) >= 3 and count_vowel(token[len(infix):]) >= 2:\n",
    "\t\t\tif token[0] == token[4] and token[1: 4] == infix:\n",
    "\t\t\t\tINFIX.append(infix)\n",
    "\t\t\t\treturn token[4:]\n",
    "\n",
    "\t\t\telif token[2] == token[4] and token[1: 3] == infix:\n",
    "\t\t\t\tINFIX.append(infix)\n",
    "\t\t\t\treturn token[0] + token[3:]\n",
    "\n",
    "\t\t\telif token[1: 3] == infix and check_vowel(token[3]):\n",
    "\t\t\t\tINFIX.append(infix)\n",
    "\t\t\t\treturn token[0] + token[3:]\n",
    "\n",
    "\treturn token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prefix(token,\t PREFIX):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for prefixes. (ex. naligo = ligo)\n",
    "\t\t\ttoken: word to be stemmed for prefixes\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tfor prefix in PREFIX_SET:\n",
    "\t\tif len(token) - len(prefix) >= 3 and \\\n",
    "\t\t\tcount_vowel(token[len(prefix):]) >= 2:\n",
    "\n",
    "\t\t\tif prefix == ('i') and check_consonant(token[2]):\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif '-' in token:\t\n",
    "\t\t\t\ttoken = token.split('-')\n",
    "\n",
    "\t\t\t\tif token[0] == prefix and check_vowel(token[1][0]):\n",
    "\t\t\t\t\tPREFIX.append(prefix)\n",
    "\t\t\t\t\treturn token[1]\n",
    "\n",
    "\t\t\t\ttoken = '-'.join(token)\n",
    "\n",
    "\t\t\tif token[0: len(prefix)] == prefix:\n",
    "\t\t\t\tif count_vowel(token[len(prefix):]) >= 2:\n",
    "\t\t\t\t\t# if check_vowel(token[len(token) - len(prefix) - 1]):\n",
    "\t\t\t\t# \tcontinue\n",
    "\n",
    "\t\t\t\t\tif prefix == 'panganga':\n",
    "\t\t\t\t\t\tPREFIX.append(prefix)\n",
    "\t\t\t\t\t\treturn 'ka' + token[len(prefix):]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tPREFIX.append(prefix)\n",
    "\t\t\t\t\treturn token[len(prefix):]\n",
    "\n",
    "\treturn token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_duplication(token, DUPLICATE):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for duplication. (ex. araw-araw = araw)\n",
    "\t\t\ttoken: word to be stemmed duplication\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tif '-' in token and token.index('-') != 0 and \\\n",
    "\t\ttoken.index('-') != len(token) -  1:\n",
    "\n",
    "\t\tsplit = token.split('-')\n",
    "\n",
    "\t\tif all(len(tok) >= 3 for tok in split):\n",
    "\t\t\tif split[0] == token[1] or split[0][-1] == 'u' and change_letter(split[0], -1, 'o') == split[1] or \\\n",
    "\t\t\t\tsplit[0][-2] == 'u' and change_letter(split[0], -2, 'o')  == split[1]:\n",
    "\t\t\t\tDUPLICATE.append(split[0])\n",
    "\t\t\t\treturn split[0]\n",
    "\n",
    "\t\t\telif split[0] == split[1][0:len(split[0])]:\n",
    "\t\t\t\tDUPLICATE.append(split[1])\n",
    "\t\t\t\treturn split[1]\n",
    "\n",
    "\t\t\telif split[0][-2:] == 'ng':\n",
    "\t\t\t\tif split[0][-3] == 'u':\n",
    "\t\t\t\t\tif split[0][0:-3] + 'o' == split[1]:\n",
    "\t\t\t\t\t\tDUPLICATE.append(split[1])\n",
    "\t\t\t\t\t\treturn split[1]\n",
    "\n",
    "\t\t\t\tif split[0][0:-2] == split[1]:\n",
    "\t\t\t\t\tDUPLICATE.append(split[1])\n",
    "\t\t\t\t\treturn split[1]\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn '-'.join(split)\n",
    "\t\n",
    "\treturn token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_repitition(token, REPITITION):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for repitition. (ex. nakakabaliw = nabaliw)\n",
    "\t\t\ttoken: word to be stemmed repitition\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tif len(token) >= 4:\n",
    "\t\tif check_vowel(token[0]):\n",
    "\t\t\tif token[0] == token[1]:\n",
    "\t\t\t\tREPITITION.append(token[0])\n",
    "\t\t\t\treturn token[1:]\n",
    "\n",
    "\t\telif check_consonant(token[0]) and count_vowel(token) >= 2:\n",
    "\t\t\tif token[0: 2] == token[2: 4] and len(token) - 2 >= 4:\n",
    "\t\t\t\tREPITITION.append(token[2:4])\n",
    "\t\t\t\treturn token[2:]\n",
    "\t\t\t\n",
    "\t\t\telif token[0: 3] == token[3: 6] and len(token) - 3 >= 4:\n",
    "\t\t\t\tREPITITION.append(token[3:6])\n",
    "\t\t\t\treturn token[3:]\n",
    "\n",
    "\treturn token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_stemmed(token, CLEANERS, REPITITION):\n",
    "\t\"\"\"\n",
    "\t\tChecks for left-over affixes and letters.\n",
    "\t\t\ttoken: word to be cleaned for excess affixes/letters\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tglobal PERIOD_FLAG\n",
    "\tglobal PASS_FLAG\n",
    "\n",
    "\tCC_EXP = ['dr', 'gl', 'gr', 'ng', 'kr', 'kl', 'kw', 'ts', 'tr', 'pr', 'pl', 'pw', 'sw', 'sy'] # Consonant + Consonant Exceptions\n",
    "\n",
    "\tif token[-1] == '.' and PASS_FLAG == False:\n",
    "\t\tPERIOD_FLAG = True\n",
    "\n",
    "\tif not check_vowel(token[-1]) and not check_consonant(token[-1]):\n",
    "\t\tCLEANERS.append(token[-1])\n",
    "\t\ttoken = token[0:-1]\n",
    "\n",
    "\tif not check_vowel(token[0]) and not check_consonant(token[0]):\n",
    "\t\tCLEANERS.append(token[0])\n",
    "\t\ttoken = token[1:]\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tif len(token) >= 3 and count_vowel(token) >= 2:\n",
    "\t\ttoken = clean_repitition(token,\tREPITITION)\n",
    "\n",
    "\t\tif check_consonant(token[-1]) and token[- 2] == 'u':\n",
    "\t\t\tCLEANERS.append('u')\n",
    "\t\t\ttoken = change_letter(token, -2, 'o')\n",
    "\n",
    "\t\tif token[len(token) - 1] == 'u':\n",
    "\t\t\tCLEANERS.append('u')\n",
    "\t\t\ttoken = change_letter(token, -1, 'o')\n",
    "\n",
    "\t\tif token[-1] == 'r':\n",
    "\t\t\tCLEANERS.append('r')\n",
    "\t\t\ttoken = change_letter(token, -1, 'd')\n",
    "\n",
    "\t\tif token[-1] == 'h' and check_vowel(token[-1]):\n",
    "\t\t\tCLEANERS.append('h')\n",
    "\t\t\ttoken = token[0:-1]\n",
    "\n",
    "\t\t# if token[0] == 'i':\n",
    "\t\t# \ttoken = token[1:]\n",
    "\n",
    "\t\tif token[0] == token[1]:\n",
    "\t\t\tCLEANERS.append(token[0])\n",
    "\t\t\ttoken = token[1:]\n",
    "\n",
    "\t\tif (token[0: 2] == 'ka' or token[0: 2] == 'pa') and check_consonant(token[2]) \\\n",
    "\t\t\tand count_vowel(token) >= 3:\n",
    "\t\t\t\n",
    "\t\t\tCLEANERS.append(token[0: 2])\n",
    "\t\t\ttoken = token[2:]\n",
    "\n",
    "\t\tif(token[-3:]) == 'han' and count_vowel(token[0:-3]) == 1:\n",
    "\t\t\tCLEANERS.append('han')\n",
    "\t\t\ttoken = token[0:-3] + 'i'\n",
    "\n",
    "\t\tif(token[-3:]) == 'han' and count_vowel(token[0:-3]) > 1:\n",
    "\t\t\tCLEANERS.append('han')\n",
    "\t\t\ttoken = token[0:-3]\n",
    "\n",
    "\t\tif len(token) >= 2 and count_vowel(token) >= 3:\n",
    "\t\t\tif token[-1] == 'h' and check_vowel(token[-2]):\n",
    "\t\t\t\tCLEANERS.append('h')\n",
    "\t\t\t\ttoken = token[0:-1]\n",
    "\n",
    "\t\tif len(token) >= 6 and token[0:2] == token[2:4]:\n",
    "\t\t\tCLEANERS.append('0:2')\n",
    "\t\t\ttoken = token[2:]\n",
    "\n",
    "\t\tif any(REP[0] == 'r' for REP in REPITITION):\n",
    "\t\t\tCLEANERS.append('r')\n",
    "\t\t\ttoken = change_letter(token, 0, 'd')\n",
    "\n",
    "\t\tif token[-2:] == 'ng' and token[-3] == 'u':\n",
    "\t\t\tCLEANERS.append('u')\n",
    "\t\t\ttoken = change_letter(token, -3, 'o')\n",
    "\n",
    "\t\tif token[-1] == 'h':\n",
    "\t\t\tCLEANERS.append('h')\n",
    "\t\t\ttoken = token[0:-1]\n",
    "\n",
    "\t\tif any(token[0:2] != CC for CC in CC_EXP) and check_consonant(token[0:2]):\n",
    "\t\t\tCLEANERS.append(token[0:2])\n",
    "\t\t\ttoken = token[1:]\n",
    "\n",
    "\treturn token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(tokens):\n",
    "\n",
    "\tglobal PERIOD_FLAG\n",
    "\tglobal PASS_FLAG\n",
    "\n",
    "\tpre_stem     = inf_stem = suf_stem = rep_stem = \\\n",
    "\t\tdu1_stem = du2_stem = cle_stem = '-'\n",
    "\tword_info    = {}\n",
    "\tPREFIX     = []\n",
    "\tINFIX      = []\n",
    "\tSUFFIX     = []\n",
    "\tDUPLICATE  = []\n",
    "\tREPITITION = []\n",
    "\tCLEANERS   = []\n",
    "\n",
    "\tfor token in tokens:\n",
    "\t\t\t\n",
    "\t\t\tword_info[\"word\"] = token\n",
    "\t\t\t\n",
    "\t\t\tif (PERIOD_FLAG == True and token[0].isupper()) or \\\n",
    "\t\t\t\t(PERIOD_FLAG == False and token[0].islower()):\n",
    "\n",
    "\t\t\t\ttoken \t = token.lower()\t\t\n",
    "\t\t\t\tdu1_stem = clean_duplication(token, DUPLICATE)\n",
    "\t\t\t\tpre_stem = clean_prefix(du1_stem, PREFIX)\n",
    "\t\t\t\trep_stem = clean_repitition(pre_stem, REPITITION)\n",
    "\t\t\t\tinf_stem = clean_infix(rep_stem, INFIX)\n",
    "\t\t\t\trep_stem = clean_repitition(inf_stem, REPITITION)\n",
    "\t\t\t\tsuf_stem = clean_suffix(rep_stem, SUFFIX)\n",
    "\t\t\t\tdu2_stem = clean_duplication(suf_stem, DUPLICATE)\n",
    "\t\t\t\tcle_stem = clean_stemmed(du2_stem, CLEANERS, REPITITION)\n",
    "\t\t\t\tcle_stem = clean_duplication(cle_stem, DUPLICATE)\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tPERIOD_FLAG = False\n",
    "\t\t\t\tcle_stem = clean_stemmed(token, CLEANERS, REPITITION)\n",
    "\t\t\t\tword_info[\"root\"]   = token\n",
    "\t\t\t\tword_info[\"prefix\"] = '[]'\n",
    "\t\t\t\tword_info[\"infix\"]  = '[]'\n",
    "\t\t\t\tword_info[\"suffix\"] = '[]'\n",
    "\t\t\t\tword_info[\"repeat\"] = '[]'\n",
    "\t\t\t\tword_info[\"dupli\"]  = '[]'\n",
    "\t\t\t\tword_info[\"clean\"]   = '[]'\n",
    "\t\t\t\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokenize'].to_csv('tokenize.txt', sep=' ', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tao : ng\n",
      "sawa : ng\n",
      "forgett : ing\n",
      "forgetti : ng\n",
      "forgettin : g\n",
      "prepar : ing\n",
      "prepari : ng\n",
      "preparin : g\n",
      "nogno : g\n",
      "nogno : g\n",
      "runni : ng\n",
      "runnin : g\n",
      "earn : ing\n",
      "earni : ng\n",
      "earnin : g\n",
      "hirap : an\n",
      "endi : ng\n",
      "endin : g\n",
      "aga : in\n",
      "nogno : g\n",
      "break : ing\n",
      "breaki : ng\n",
      "breakin : g\n",
      "ito : ng\n",
      "niyo : ng\n",
      "batikus : in\n",
      "talaga : ng\n",
      "para : ng\n",
      "gusto : ng\n",
      "hirapa : ng\n",
      "para : ng\n",
      "kipa : g\n",
      "talun : in\n",
      "bei : ng\n",
      "bein : g\n",
      "para : ng\n",
      "uili : an\n",
      "kair : ita\n",
      "goberna : dor\n",
      "salamat : an\n",
      "nakaw : an\n",
      "handa : ng\n",
      "ibago : ng\n",
      "nogno : g\n",
      "stumpi : ng\n",
      "stumpin : g\n",
      "talaga : ng\n",
      "calli : ng\n",
      "callin : g\n",
      "bayar : an\n",
      "tanung : in\n",
      "inta : ng\n",
      "intan : g\n",
      "basa : hin\n",
      "endors : ing\n",
      "endorsi : ng\n",
      "endorsin : g\n",
      "tulung : an\n",
      "ombudsm : an\n",
      "kelang : an\n",
      "itim : in\n",
      "tuwa : ng\n",
      "tau : ng\n",
      "taun : g\n",
      "annoy : ing\n",
      "annoyi : ng\n",
      "annoyin : g\n",
      "ano : ng\n",
      "andam : ing\n",
      "andami : ng\n",
      "syado : ng\n",
      "syadon : g\n",
      "sobra : ng\n",
      "givi : ng\n",
      "givin : g\n",
      "earn : ing\n",
      "earni : ng\n",
      "earnin : g\n",
      "syado : ng\n",
      "syadon : g\n",
      "halata : ng\n",
      "daa : ng\n",
      "daan : g\n",
      "risi : ng\n",
      "risin : g\n",
      "kair : ita\n",
      "nothi : ng\n",
      "nothin : g\n",
      "gawi : ng\n",
      "igi : ng\n",
      "suporta : han\n",
      "kilalan : in\n",
      "sabi : ng\n",
      "baytular : an\n",
      "upris : ing\n",
      "uprisi : ng\n",
      "uprisin : g\n",
      "ako : ng\n",
      "muda : ng\n",
      "mudan : g\n",
      "kayo : ng\n",
      "daa : ng\n",
      "daan : g\n",
      "nala : ng\n",
      "nalan : g\n",
      "nala : ng\n",
      "nalan : g\n",
      "aga : in\n",
      "para : ng\n",
      "nala : ng\n",
      "nalan : g\n",
      "nala : ng\n",
      "nalan : g\n",
      "nogno : g\n",
      "salan : an\n",
      "bongbo : ng\n",
      "bongbon : g\n",
      "nala : ng\n",
      "nalan : g\n",
      "daya : an\n",
      "someth : ing\n",
      "somethi : ng\n",
      "somethin : g\n",
      "showi : ng\n",
      "showin : g\n",
      "hirap : an\n",
      "nala : ng\n",
      "nalan : g\n",
      "nakaw : an\n",
      "bongbo : ng\n",
      "bongbon : g\n",
      "alo : ng\n",
      "alon : g\n",
      "babbli : ng\n",
      "babblin : g\n",
      "regard : ing\n",
      "regardi : ng\n",
      "regardin : g\n",
      "nothi : ng\n",
      "nothin : g\n",
      "sakit : in\n",
      "syado : ng\n",
      "syadon : g\n",
      "tigil : an\n",
      "tao : ng\n",
      "laru : an\n",
      "mukha : ng\n",
      "killi : ng\n",
      "killin : g\n",
      "nami : ng\n",
      "namin : g\n",
      "nogno : g\n",
      "ndidato : ng\n",
      "ndidaton : g\n",
      "aga : in\n",
      "honas : an\n",
      "nala : ng\n",
      "nalan : g\n",
      "sira : an\n",
      "una : ng\n",
      "tira : hin\n",
      "abut : in\n",
      "someth : ing\n",
      "somethi : ng\n",
      "somethin : g\n",
      "enlighten : ing\n",
      "enlighteni : ng\n",
      "enlightenin : g\n",
      "comi : ng\n",
      "comin : g\n",
      "eto : ng\n",
      "nogno : g\n",
      "tuwi : ng\n",
      "compla : in\n",
      "daa : ng\n",
      "daan : g\n",
      "risi : ng\n",
      "risin : g\n",
      "reach : ing\n",
      "reachi : ng\n",
      "reachin : g\n",
      "hindi : ng\n",
      "runni : ng\n",
      "runnin : g\n",
      "hirap : an\n",
      "ano : ng\n",
      "bongbo : ng\n",
      "bongbon : g\n",
      "runni : ng\n",
      "runnin : g\n",
      "nala : ng\n",
      "nalan : g\n",
      "amba : g\n",
      "nogno : g\n",
      "gather : ing\n",
      "gatheri : ng\n",
      "gatherin : g\n",
      "dati : ng\n",
      "showi : ng\n",
      "showin : g\n",
      "kahinatn : an\n",
      "hatul : an\n",
      "nogno : g\n",
      "pondo : han\n",
      "kala : ng\n",
      "bata : ng\n",
      "nogno : g\n",
      "nogno : g\n",
      "kibigy : an\n",
      "nala : ng\n",
      "nalan : g\n",
      "tawag : an\n",
      "kalimut : an\n",
      "sayi : ng\n",
      "sayin : g\n",
      "para : ng\n",
      "gusto : ng\n",
      "balay : an\n",
      "nala : ng\n",
      "nalan : g\n",
      "tigil : in\n",
      "ulit : in\n",
      "laban : an\n",
      "sumpa : in\n",
      "ako : ng\n",
      "tulung : an\n",
      "nogno : g\n",
      "tayo : ng\n",
      "havi : ng\n",
      "havin : g\n",
      "voti : ng\n",
      "votin : g\n",
      "honas : an\n",
      "duri : ng\n",
      "durin : g\n",
      "para : ng\n",
      "hanap : in\n",
      "sakal : ing\n",
      "skali : ng\n",
      "skalin : g\n",
      "tao : ng\n",
      "patugto : g\n",
      "pwede : ng\n",
      "samapa : ng\n",
      "samapan : g\n",
      "ombudsm : an\n",
      "nala : ng\n",
      "nalan : g\n",
      "americ : an\n",
      "ungus : an\n",
      "havi : ng\n",
      "havin : g\n",
      "churi : an\n",
      "huli : ng\n",
      "gobyerno : ng\n",
      "gobyerno : ng\n",
      "uor : in\n",
      "pina : g\n",
      "sira : an\n",
      "doi : ng\n",
      "doin : g\n",
      "eat : ing\n",
      "eati : ng\n",
      "eatin : g\n",
      "smili : ng\n",
      "smilin : g\n",
      "sampa : han\n",
      "bago : ng\n",
      "ombudsm : an\n",
      "nogno : g\n",
      "support : ing\n",
      "supporti : ng\n",
      "supportin : g\n",
      "bigla : ng\n",
      "aga : in\n",
      "sayi : ng\n",
      "sayin : g\n",
      "paliwana : g\n",
      "paliwana : g\n",
      "dami : ng\n",
      "kair : ita\n",
      "nogno : g\n",
      "compla : in\n",
      "kaisa : han\n",
      "feel : ing\n",
      "feeli : ng\n",
      "feelin : g\n",
      "turni : ng\n",
      "turnin : g\n",
      "certa : in\n",
      "lifelo : ng\n",
      "lifelon : g\n",
      "kita : ng\n",
      "kaawa : an\n",
      "endors : ing\n",
      "endorsi : ng\n",
      "endorsin : g\n",
      "gamit : in\n",
      "honas : an\n",
      "igi : ng\n",
      "nala : ng\n",
      "nalan : g\n",
      "nogno : g\n",
      "nogno : g\n",
      "sami : ng\n",
      "samin : g\n",
      "proklama : ng\n",
      "proklaman : g\n",
      "sira : an\n",
      "starti : ng\n",
      "startin : g\n",
      "daa : ng\n",
      "daan : g\n",
      "honas : an\n",
      "sulo : g\n",
      "wasti : ng\n",
      "wastin : g\n",
      "digo : ng\n",
      "digon : g\n",
      "nala : ng\n",
      "nalan : g\n",
      "kuha : ng\n",
      "kuhan : g\n",
      "regard : ing\n",
      "regardi : ng\n",
      "regardin : g\n",
      "walo : ng\n",
      "kalawa : ng\n",
      "kalawan : g\n",
      "noo : ng\n",
      "raa : ng\n",
      "raan : g\n",
      "pulli : ng\n",
      "pullin : g\n",
      "pede : ng\n",
      "nogno : g\n",
      "punyeta : ng\n",
      "punyetan : g\n",
      "nama : ng\n",
      "naman : g\n",
      "gentlem : an\n",
      "sobra : ng\n",
      "nogno : g\n",
      "describ : ing\n",
      "describi : ng\n",
      "describin : g\n",
      "visit : ing\n",
      "visiti : ng\n",
      "visitin : g\n",
      "leav : ing\n",
      "leavi : ng\n",
      "leavin : g\n",
      "duri : ng\n",
      "durin : g\n",
      "meet : ing\n",
      "meeti : ng\n",
      "meetin : g\n",
      "surpris : ing\n",
      "surprisi : ng\n",
      "surprisin : g\n",
      "casemari : ing\n",
      "casemarii : ng\n",
      "casemariin : g\n",
      "alma : han\n",
      "almah : an\n",
      "laca : ang\n",
      "lacaa : ng\n",
      "lacaan : g\n",
      "garapal : an\n",
      "lalo : ng\n",
      "rami : ng\n",
      "offer : an\n",
      "tanggi : han\n",
      "oras : an\n",
      "comi : ng\n",
      "comin : g\n",
      "steppi : ng\n",
      "steppin : g\n",
      "alawa : ng\n",
      "alawan : g\n",
      "daluyo : ng\n",
      "daluyon : g\n",
      "embarrass : ing\n",
      "embarrassi : ng\n",
      "embarrassin : g\n",
      "sila : ng\n",
      "tapus : an\n",
      "kami : ng\n",
      "nogno : g\n",
      "para : ng\n",
      "limling : an\n",
      "ebe : ng\n",
      "eben : g\n",
      "kapa : g\n",
      "tao : ng\n",
      "feel : ing\n",
      "feeli : ng\n",
      "feelin : g\n",
      "palpak : an\n",
      "nala : ng\n",
      "nalan : g\n",
      "niyo : ng\n",
      "siya : ng\n",
      "nala : ng\n",
      "nalan : g\n",
      "kasaril : ing\n",
      "kasarili : ng\n",
      "kasarilin : g\n",
      "tao : ng\n",
      "ato : ng\n",
      "aton : g\n",
      "getti : ng\n",
      "gettin : g\n",
      "nogno : g\n",
      "pari : ng\n",
      "usi : ng\n",
      "usin : g\n",
      "hashta : g\n",
      "nogno : g\n",
      "curta : in\n",
      "rais : ing\n",
      "raisi : ng\n",
      "raisin : g\n",
      "putti : ng\n",
      "puttin : g\n",
      "nogno : g\n",
      "beginn : ing\n",
      "beginni : ng\n",
      "beginnin : g\n",
      "exclud : ing\n",
      "excludi : ng\n",
      "excludin : g\n",
      "tropa : ng\n",
      "rami : ng\n",
      "honas : an\n",
      "ilya : ng\n",
      "ilyan : g\n",
      "cludi : ng\n",
      "cludin : g\n",
      "americ : an\n",
      "limling : an\n",
      "choos : ing\n",
      "choosi : ng\n",
      "choosin : g\n",
      "igi : ng\n",
      "una : hin\n",
      "ayus : in\n",
      "tanggal : in\n",
      "bumyahe : ng\n",
      "bumyahen : g\n",
      "habul : in\n",
      "pngsama : han\n",
      "pngsamah : an\n",
      "para : ng\n",
      "puta : ng\n",
      "patunay : an\n",
      "honas : an\n",
      "nala : ng\n",
      "nalan : g\n",
      "tular : an\n",
      "nogno : g\n",
      "lead : ing\n",
      "leadi : ng\n",
      "leadin : g\n",
      "campaign : ing\n",
      "campaigni : ng\n",
      "campaignin : g\n",
      "katawa : ng\n",
      "katawan : g\n",
      "support : ing\n",
      "supporti : ng\n",
      "supportin : g\n",
      "nogno : g\n",
      "blami : ng\n",
      "blamin : g\n",
      "nogno : g\n",
      "kami : ng\n",
      "accord : ing\n",
      "accordi : ng\n",
      "accordin : g\n",
      "watchi : ng\n",
      "watchin : g\n",
      "nogno : g\n",
      "abusado : ng\n",
      "amus : ing\n",
      "amusi : ng\n",
      "amusin : g\n",
      "tradi : ng\n",
      "tradin : g\n",
      "sawa : ng\n",
      "usi : ng\n",
      "usin : g\n",
      "protect : ing\n",
      "protecti : ng\n",
      "protectin : g\n",
      "sana : ng\n",
      "nakaw : an\n",
      "subra : ng\n",
      "subran : g\n",
      "sayi : ng\n",
      "sayin : g\n",
      "plunder : ing\n",
      "plunderi : ng\n",
      "plunderin : g\n",
      "abut : in\n",
      "compar : ing\n",
      "compari : ng\n",
      "comparin : g\n",
      "duri : ng\n",
      "durin : g\n",
      "duri : ng\n",
      "durin : g\n",
      "miti : ng\n",
      "mitin : g\n",
      "sila : ng\n",
      "ayus : in\n",
      "nogno : g\n",
      "sobra : ng\n",
      "nogno : g\n",
      "hous : ing\n",
      "housi : ng\n",
      "housin : g\n",
      "muka : ng\n",
      "mukan : g\n",
      "taclob : an\n",
      "speak : ing\n",
      "speaki : ng\n",
      "speakin : g\n",
      "abut : in\n",
      "endors : ing\n",
      "endorsi : ng\n",
      "endorsin : g\n",
      "uor : in\n",
      "tapat : an\n",
      "hirap : an\n",
      "mali : ng\n",
      "malin : g\n",
      "support : ing\n",
      "supporti : ng\n",
      "supportin : g\n",
      "taas : an\n",
      "nogno : g\n",
      "tambal : an\n",
      "endors : ing\n",
      "endorsi : ng\n",
      "endorsin : g\n",
      "daya : an\n",
      "nothi : ng\n",
      "nothin : g\n",
      "rati : ng\n",
      "ratin : g\n",
      "daa : ng\n",
      "daan : g\n",
      "nama : ng\n",
      "naman : g\n",
      "daya : in\n",
      "ali : ng\n",
      "alin : g\n",
      "honas : an\n",
      "putti : ng\n",
      "puttin : g\n",
      "nothi : ng\n",
      "nothin : g\n",
      "limling : an\n",
      "acti : ng\n",
      "actin : g\n",
      "igi : ng\n",
      "daya : in\n",
      "mukha : ng\n",
      "selli : ng\n",
      "sellin : g\n",
      "chile : an\n",
      "mexic : an\n",
      "voti : ng\n",
      "votin : g\n",
      "luto : ng\n",
      "playi : ng\n",
      "playin : g\n",
      "nala : ng\n",
      "nalan : g\n",
      "sari : ng\n",
      "para : ng\n",
      "laki : ng\n",
      "ulo : ng\n",
      "comi : ng\n",
      "comin : g\n",
      "bai : han\n",
      "baih : an\n",
      "fucki : ng\n",
      "fuckin : g\n",
      "nothi : ng\n",
      "nothin : g\n",
      "nogno : g\n",
      "suporta : han\n",
      "nogno : g\n",
      "uta : ng\n",
      "utan : g\n",
      "tuwidnada : an\n",
      "ramdam : an\n",
      "nogno : g\n",
      "sendi : ng\n",
      "sendin : g\n",
      "goi : ng\n",
      "goin : g\n",
      "dali : hin\n",
      "pina : g\n",
      "usap : an\n",
      "baypa : g\n",
      "baytular : an\n",
      "nogno : g\n",
      "kasi : ng\n",
      "rami : ng\n",
      "awa : ng\n",
      "putangina : ng\n",
      "sayi : ng\n",
      "sayin : g\n",
      "niwala : ng\n",
      "niwalan : g\n",
      "sira : an\n",
      "kaya : ng\n",
      "banggit : in\n",
      "coat : ing\n",
      "coati : ng\n",
      "coatin : g\n",
      "glari : ng\n",
      "glarin : g\n",
      "tayo : ng\n",
      "someth : ing\n",
      "somethi : ng\n",
      "somethin : g\n",
      "lagi : ng\n",
      "calli : ng\n",
      "callin : g\n",
      "una : han\n",
      "nogno : g\n",
      "honas : an\n",
      "sampal : in\n",
      "sampal : in\n",
      "asa : ng\n",
      "asan : g\n",
      "isip : in\n",
      "campaign : ing\n",
      "campaigni : ng\n",
      "campaignin : g\n",
      "limling : an\n",
      "remember : ing\n",
      "rememberi : ng\n",
      "rememberin : g\n",
      "duri : ng\n",
      "durin : g\n",
      "wait : ing\n",
      "waiti : ng\n",
      "waitin : g\n",
      "goi : ng\n",
      "goin : g\n",
      "nogno : g\n",
      "maki : ng\n",
      "makin : g\n",
      "pulut : in\n",
      "cabag : an\n",
      "clamour : ing\n",
      "clamouri : ng\n",
      "clamourin : g\n",
      "smili : ng\n",
      "smilin : g\n",
      "bulac : an\n",
      "nito : ng\n",
      "pakulo : ng\n",
      "pakulon : g\n",
      "igi : ng\n",
      "dami : ng\n",
      "dami : ng\n",
      "abut : in\n",
      "talki : ng\n",
      "talkin : g\n",
      "daa : ng\n",
      "daan : g\n",
      "para : ng\n",
      "tuwi : ng\n",
      "dami : ng\n",
      "asin : an\n",
      "graspi : ng\n",
      "graspin : g\n",
      "wait : ing\n",
      "waiti : ng\n",
      "waitin : g\n",
      "ispaget : ing\n",
      "ispageti : ng\n",
      "ispagetin : g\n",
      "salan : an\n",
      "nogno : g\n",
      "root : ing\n",
      "rooti : ng\n",
      "rootin : g\n",
      "ito : ng\n",
      "trendi : ng\n",
      "trendin : g\n",
      "getti : ng\n",
      "gettin : g\n",
      "frustrat : ing\n",
      "frustrati : ng\n",
      "frustratin : g\n",
      "bei : ng\n",
      "bein : g\n",
      "tangi : an\n",
      "kayo : ng\n",
      "nogno : g\n",
      "mukha : ng\n",
      "dati : ng\n",
      "tayo : ng\n",
      "ilya : ng\n",
      "ilyan : g\n",
      "conta : in\n",
      "ongo : ing\n",
      "ongoi : ng\n",
      "ongoin : g\n",
      "comi : ng\n",
      "comin : g\n",
      "halata : ng\n",
      "sanggano : ng\n",
      "sangganon : g\n",
      "siya : ng\n",
      "nama : ng\n",
      "naman : g\n",
      "taclob : an\n",
      "shari : ng\n",
      "sharin : g\n",
      "hidi : ng\n",
      "hidin : g\n",
      "sila : ng\n",
      "duri : ng\n",
      "durin : g\n",
      "buyi : ng\n",
      "buyin : g\n",
      "saril : ing\n",
      "sarili : ng\n",
      "una : ng\n",
      "asa : han\n",
      "asah : an\n",
      "labo : ng\n",
      "mura : hin\n",
      "talaga : ng\n",
      "remember : ing\n",
      "rememberi : ng\n",
      "rememberin : g\n",
      "open : ing\n",
      "openi : ng\n",
      "openin : g\n",
      "uor : in\n",
      "nama : ng\n",
      "naman : g\n",
      "tohan : an\n",
      "calli : ng\n",
      "callin : g\n",
      "fifeel : ing\n",
      "fifeeli : ng\n",
      "fifeelin : g\n",
      "deliver : ing\n",
      "deliveri : ng\n",
      "deliverin : g\n",
      "miti : ng\n",
      "mitin : g\n",
      "spread : ing\n",
      "spreadi : ng\n",
      "spreadin : g\n",
      "sandig : an\n",
      "iba : ng\n",
      "bago : ng\n",
      "wait : ing\n",
      "waiti : ng\n",
      "waitin : g\n",
      "voti : ng\n",
      "votin : g\n",
      "voti : ng\n",
      "votin : g\n",
      "sobra : ng\n",
      "spread : ing\n",
      "spreadi : ng\n",
      "spreadin : g\n",
      "iya : ng\n",
      "iyan : g\n",
      "putangina : ng\n",
      "lead : ing\n",
      "leadi : ng\n",
      "leadin : g\n",
      "ombudsm : an\n",
      "lait : in\n",
      "igi : ng\n",
      "boto : ng\n",
      "lawig : an\n",
      "ngayo : ng\n",
      "ngayon : g\n",
      "talki : ng\n",
      "talkin : g\n",
      "ruli : ng\n",
      "rulin : g\n",
      "sobra : ng\n",
      "nala : ng\n",
      "nalan : g\n",
      "daan : an\n",
      "nancya : ng\n",
      "nancyan : g\n",
      "dati : ng\n",
      "ano : ng\n",
      "morni : ng\n",
      "mornin : g\n",
      "dami : ng\n",
      "nala : ng\n",
      "nalan : g\n",
      "morni : ng\n",
      "mornin : g\n",
      "limut : an\n",
      "kayo : ng\n",
      "ako : ng\n",
      "dami : ng\n",
      "witness : ing\n",
      "witnessi : ng\n",
      "witnessin : g\n",
      "command : ing\n",
      "commandi : ng\n",
      "commandin : g\n",
      "pili : in\n",
      "dandi : ng\n",
      "dandin : g\n",
      "nama : ng\n",
      "naman : g\n",
      "handa : ng\n",
      "hula : an\n",
      "teenk : ing\n",
      "teenki : ng\n",
      "teenkin : g\n",
      "iniwala : ng\n",
      "para : ng\n",
      "iniwala : ng\n",
      "daa : ng\n",
      "daan : g\n",
      "bongbo : ng\n",
      "bongbon : g\n",
      "trendi : ng\n",
      "trendin : g\n",
      "calli : ng\n",
      "callin : g\n",
      "manni : ng\n",
      "mannin : g\n",
      "duri : ng\n",
      "durin : g\n",
      "laki : ng\n",
      "nito : ng\n",
      "usap : an\n",
      "goi : ng\n",
      "goin : g\n",
      "sayi : ng\n",
      "sayin : g\n",
      "sana : ng\n",
      "ganda : han\n",
      "buti : hin\n",
      "damiram : ing\n",
      "damirami : ng\n",
      "damiramin : g\n",
      "salan : an\n",
      "para : ng\n",
      "igi : ng\n",
      "standi : ng\n",
      "standin : g\n",
      "standi : ng\n",
      "standin : g\n",
      "sobra : ng\n",
      "boto : hin\n",
      "puta : ng\n",
      "laban : an\n",
      "talaga : ng\n",
      "para : ng\n",
      "kami : ng\n",
      "tanga : han\n",
      "ito : ng\n",
      "para : ng\n",
      "para : ng\n",
      "kami : ng\n",
      "nogno : g\n",
      "karebolu : syon\n",
      "support : ing\n",
      "supporti : ng\n",
      "supportin : g\n",
      "kulto : ng\n",
      "lasa : ng\n",
      "dami : ng\n",
      "pwede : ng\n",
      "featur : ing\n",
      "featuri : ng\n",
      "featurin : g\n",
      "bei : ng\n",
      "bein : g\n",
      "nogno : g\n",
      "korni : ng\n",
      "kornin : g\n",
      "expect : ing\n",
      "expecti : ng\n",
      "expectin : g\n",
      "rami : ng\n",
      "patunay : an\n",
      "dati : ng\n",
      "turo : ng\n",
      "ako : ng\n",
      "appeal : ing\n",
      "appeali : ng\n",
      "appealin : g\n",
      "sabi : han\n",
      "pare : ng\n",
      "pangalan : an\n",
      "pasi : g\n",
      "daluyo : ng\n",
      "daluyon : g\n",
      "viti : ng\n",
      "vitin : g\n",
      "meet : ing\n",
      "meeti : ng\n",
      "meetin : g\n",
      "tiwali : an\n",
      "layo : ng\n",
      "sira : in\n",
      "featur : ing\n",
      "featuri : ng\n",
      "featurin : g\n",
      "calli : ng\n",
      "callin : g\n",
      "doi : ng\n",
      "doin : g\n",
      "salan : an\n",
      "nala : ng\n",
      "nalan : g\n",
      "para : ng\n",
      "lako : ng\n",
      "kaibig : an\n",
      "crimefight : ing\n",
      "crimefighti : ng\n",
      "crimefightin : g\n",
      "honas : an\n",
      "katiti : g\n",
      "halata : ng\n",
      "too : ng\n",
      "nakaw : an\n",
      "hlaga : ng\n",
      "hlagan : g\n",
      "lagi : ng\n",
      "ano : ng\n",
      "upu : an\n",
      "someth : ing\n",
      "somethi : ng\n",
      "somethin : g\n",
      "pushi : ng\n",
      "pushin : g\n",
      "bongbo : ng\n",
      "bongbon : g\n",
      "una : hin\n",
      "payi : ng\n",
      "payin : g\n",
      "overha : ng\n",
      "overhan : g\n",
      "taclob : an\n",
      "issue : ng\n",
      "issuen : g\n",
      "mali : ng\n",
      "malin : g\n",
      "usi : ng\n",
      "usin : g\n",
      "nothi : ng\n",
      "nothin : g\n",
      "nala : ng\n",
      "nalan : g\n",
      "sakal : ing\n",
      "digo : ng\n",
      "digon : g\n",
      "draggi : ng\n",
      "draggin : g\n",
      "muka : ng\n",
      "mukan : g\n",
      "nothi : ng\n",
      "nothin : g\n",
      "bashi : ng\n",
      "bashin : g\n",
      "ali : ng\n",
      "alin : g\n",
      "kayo : ng\n",
      "givi : ng\n",
      "givin : g\n",
      "tigil : an\n",
      "droppi : ng\n",
      "droppin : g\n",
      "nogno : g\n",
      "americ : an\n",
      "launch : ing\n",
      "launchi : ng\n",
      "launchin : g\n",
      "anythi : ng\n",
      "anythin : g\n",
      "goi : ng\n",
      "goin : g\n",
      "samantala : ng\n",
      "kame : ng\n",
      "kamen : g\n",
      "gamit : in\n",
      "laban : an\n",
      "goi : ng\n",
      "goin : g\n",
      "putti : ng\n",
      "puttin : g\n",
      "neglect : ing\n",
      "neglecti : ng\n",
      "neglectin : g\n",
      "regard : ing\n",
      "regardi : ng\n",
      "regardin : g\n",
      "pakull : ng\n",
      "pakulln : g\n",
      "punyeta : ng\n",
      "punyetan : g\n",
      "isa : han\n",
      "ipili : an\n",
      "tambala : ng\n",
      "tambalan : g\n",
      "bilang : an\n",
      "aga : in\n",
      "lagi : ng\n",
      "konti : ng\n",
      "sana : ng\n",
      "nogno : g\n",
      "intidi : han\n",
      "intidih : an\n",
      "ombudsm : an\n",
      "cosal : an\n",
      "daa : ng\n",
      "daan : g\n",
      "daya : an\n",
      "alam : an\n",
      "livi : ng\n",
      "livin : g\n",
      "address : ing\n",
      "addressi : ng\n",
      "addressin : g\n",
      "hirap : an\n",
      "hirap : an\n",
      "dilim : an\n",
      "kami : ng\n",
      "nogno : g\n",
      "bago : ng\n",
      "tuwi : ng\n",
      "combin : ing\n",
      "combini : ng\n",
      "combinin : g\n",
      "certa : in\n",
      "sayi : ng\n",
      "sayin : g\n",
      "showi : ng\n",
      "showin : g\n",
      "join : ing\n",
      "joini : ng\n",
      "joinin : g\n",
      "maki : ng\n",
      "makin : g\n",
      "testi : ng\n",
      "testin : g\n",
      "gmanewsbreak : ing\n",
      "gmanewsbreaki : ng\n",
      "gmanewsbreakin : g\n",
      "gastus : an\n",
      "hirap : an\n",
      "ako : ng\n",
      "bago : ng\n",
      "nogno : g\n",
      "sagut : in\n",
      "katakut : an\n",
      "trendi : ng\n",
      "trendin : g\n",
      "kapa : g\n",
      "duri : ng\n",
      "durin : g\n",
      "read : ing\n",
      "readi : ng\n",
      "readin : g\n",
      "cabanatu : an\n",
      "nama : ng\n",
      "naman : g\n",
      "gapang : an\n",
      "distribut : ing\n",
      "distributi : ng\n",
      "distributin : g\n",
      "bayar : an\n",
      "honas : an\n",
      "nala : ng\n",
      "nalan : g\n",
      "shoot : ing\n",
      "shooti : ng\n",
      "shootin : g\n",
      "ano : ng\n",
      "gagu : han\n",
      "gaguh : an\n",
      "pwede : ng\n",
      "nala : ng\n",
      "nalan : g\n",
      "nala : ng\n",
      "nalan : g\n",
      "viti : ng\n",
      "vitin : g\n",
      "moro : ng\n",
      "draggi : ng\n",
      "draggin : g\n",
      "renounc : ing\n",
      "renounci : ng\n",
      "renouncin : g\n",
      "yari : ng\n",
      "nami : ng\n",
      "namin : g\n",
      "nogno : g\n",
      "kelanga : ng\n",
      "kelangan : g\n",
      "pili : in\n",
      "conta : in\n",
      "fucki : ng\n",
      "fuckin : g\n",
      "trendi : ng\n",
      "trendin : g\n",
      "winni : ng\n",
      "winnin : g\n",
      "tama : ng\n",
      "bau : an\n",
      "ano : ng\n",
      "tarpaul : in\n",
      "honas : an\n",
      "aski : ng\n",
      "askin : g\n",
      "gamit : in\n",
      "sali : ng\n",
      "salin : g\n",
      "igi : ng\n",
      "sobra : ng\n",
      "kair : ita\n",
      "nogno : g\n",
      "para : ng\n",
      "sawsaw : an\n",
      "sampa : han\n",
      "bago : ng\n",
      "ombudsm : an\n",
      "aski : ng\n",
      "askin : g\n",
      "batu : hin\n",
      "batuh : in\n",
      "nogno : g\n",
      "grabe : han\n",
      "daya : an\n",
      "talaga : ng\n",
      "sagut : in\n",
      "anda : ng\n",
      "butas : an\n",
      "launder : ing\n",
      "launderi : ng\n",
      "launderin : g\n",
      "mislead : ing\n",
      "misleadi : ng\n",
      "misleadin : g\n",
      "ako : ng\n",
      "hindi : ng\n",
      "nama : ng\n",
      "naman : g\n",
      "pera : han\n",
      "ruli : ng\n",
      "rulin : g\n",
      "hous : ing\n",
      "housi : ng\n",
      "housin : g\n",
      "backlo : g\n",
      "calli : ng\n",
      "callin : g\n",
      "nama : ng\n",
      "naman : g\n",
      "para : ng\n",
      "nogno : g\n",
      "eat : ing\n",
      "eati : ng\n",
      "eatin : g\n",
      "mini : ng\n",
      "minin : g\n",
      "kayo : ng\n",
      "rapata : ng\n",
      "rapatan : g\n",
      "husga : han\n",
      "husgah : an\n",
      "kalimut : an\n",
      "ako : ng\n",
      "kaba : han\n",
      "kaya : ng\n",
      "ombudsm : an\n",
      "americ : an\n",
      "lacana : ng\n",
      "lacanan : g\n",
      "tuluy : an\n",
      "gagu : han\n",
      "gaguh : an\n",
      "bongbo : ng\n",
      "bongbon : g\n",
      "miti : ng\n",
      "mitin : g\n",
      "eksena : ng\n",
      "dati : ng\n",
      "daluyo : ng\n",
      "daluyon : g\n",
      "para : ng\n",
      "bei : ng\n",
      "bein : g\n",
      "duri : ng\n",
      "durin : g\n",
      "nogno : g\n",
      "nogno : g\n",
      "sungaling : an\n",
      "kayo : ng\n",
      "joki : ng\n",
      "jokin : g\n",
      "punta : ng\n",
      "nakaw : an\n",
      "nogno : g\n",
      "hopi : ng\n",
      "hopin : g\n",
      "bata : an\n",
      "sino : ng\n",
      "sinon : g\n",
      "loko : han\n",
      "igi : ng\n",
      "aga : in\n",
      "pnapak : ita\n",
      "arestu : hin\n",
      "arestuh : in\n",
      "arestu : hin\n",
      "arestuh : in\n",
      "ici : an\n",
      "para : ng\n",
      "bola : han\n",
      "uguk : an\n",
      "andiy : an\n",
      "break : ing\n",
      "breaki : ng\n",
      "breakin : g\n",
      "loom : ing\n",
      "loomi : ng\n",
      "loomin : g\n",
      "resti : ng\n",
      "restin : g\n",
      "hashta : g\n",
      "salan : an\n",
      "rolli : ng\n",
      "rollin : g\n",
      "ombudsm : an\n",
      "bagyo : ng\n",
      "taclob : an\n",
      "maki : ng\n",
      "makin : g\n",
      "kair : ita\n",
      "dami : ng\n",
      "drama : han\n",
      "daluyo : ng\n",
      "daluyon : g\n",
      "sira : an\n",
      "nogno : g\n",
      "ito : ng\n",
      "kapal : an\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[357], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Perform stemming\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train[\u001b[39m'\u001b[39m\u001b[39mstemmed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train[\u001b[39m'\u001b[39;49m\u001b[39mtokenize\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(stemmer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[349], line 31\u001b[0m, in \u001b[0;36mstemmer\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m     29\u001b[0m \tsuf_stem \u001b[39m=\u001b[39m clean_suffix(rep_stem, SUFFIX)\n\u001b[0;32m     30\u001b[0m \tdu2_stem \u001b[39m=\u001b[39m clean_duplication(suf_stem, DUPLICATE)\n\u001b[1;32m---> 31\u001b[0m \tcle_stem \u001b[39m=\u001b[39m clean_stemmed(du2_stem, CLEANERS, REPITITION)\n\u001b[0;32m     32\u001b[0m \tcle_stem \u001b[39m=\u001b[39m clean_duplication(cle_stem, DUPLICATE)\n\u001b[0;32m     34\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[348], line 20\u001b[0m, in \u001b[0;36mclean_stemmed\u001b[1;34m(token, CLEANERS, REPITITION)\u001b[0m\n\u001b[0;32m     17\u001b[0m \tCLEANERS\u001b[39m.\u001b[39mappend(token[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     18\u001b[0m \ttoken \u001b[39m=\u001b[39m token[\u001b[39m0\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_vowel(token[\u001b[39m0\u001b[39;49m]) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m check_consonant(token[\u001b[39m0\u001b[39m]):\n\u001b[0;32m     21\u001b[0m \tCLEANERS\u001b[39m.\u001b[39mappend(token[\u001b[39m0\u001b[39m])\n\u001b[0;32m     22\u001b[0m \ttoken \u001b[39m=\u001b[39m token[\u001b[39m1\u001b[39m:]\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# Perform stemming\n",
    "train['stemmed'] = train['tokenize'].apply(stemmer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
