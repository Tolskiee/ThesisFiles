{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "#Model imports \n",
    "from sklearn import svm, metrics\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Data preprocessing imports\n",
    "import re\n",
    "import nltk\n",
    "import preprocessor as p\n",
    "from nltk.tokenize import WhitespaceTokenizer, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#Model selection and evaluation imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, confusion_matrix, classification_report, roc_curve, auc\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import psutil\n",
    "\n",
    "#plotting imports\n",
    "import matplotlib.pyplot as plt \n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train = pd.read_csv(r\".\\hatespeech\\train.csv\", nrows=10000)\n",
    "\n",
    "# testing data\n",
    "test = pd.read_csv(r\".\\hatespeech\\test.csv\", nrows=10000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaasahan na ni Vice President Jejomar Binay n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@rapplerdotcom putangina mo binay TAKBO PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binay with selective amnesia, forgetting about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Mar Roxas on the rise, w/ momentum, machinery,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>@chelseapailmao</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Alan Cayetano 'confirms' Palace, Roxas, Poe be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Mas nakakainis ad ni Mar kaysa kay Binay.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Preliminary and partial results coming in sugg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Inaasahan na ni Vice President Jejomar Binay n...      0\n",
       "1     Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...      1\n",
       "2     Salamat sa walang sawang suporta ng mga taga m...      0\n",
       "3            @rapplerdotcom putangina mo binay TAKBO PA      1\n",
       "4     Binay with selective amnesia, forgetting about...      0\n",
       "...                                                 ...    ...\n",
       "9995  Mar Roxas on the rise, w/ momentum, machinery,...      0\n",
       "9996                                    @chelseapailmao      1\n",
       "9997  Alan Cayetano 'confirms' Palace, Roxas, Poe be...      0\n",
       "9998          Mas nakakainis ad ni Mar kaysa kay Binay.      1\n",
       "9999  Preliminary and partial results coming in sugg...      0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with null values\n",
    "train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values in train\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5340"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for 0 values in train\n",
    "sum(train[\"label\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4660"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for 1 values in train\n",
    "sum(train[\"label\"] == 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data of unwated Text and Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "    tempArr = []\n",
    "    for line in df:\n",
    "        # send to tweet_processor\n",
    "        tmpL = p.clean(line)\n",
    "        # remove everything except letters and digits\n",
    "        tmpL = re.sub(r'[^a-zA-Z0-9\\s]', ' ', tmpL)\n",
    "        # convert to lowercase\n",
    "        tmpL = tmpL.lower()\n",
    "        tempArr.append(tmpL)\n",
    "    return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean training data\n",
    "train_tweet = clean_tweets(train[\"text\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append cleaned tweets to the training data\n",
    "train[\"clean_tweet\"] = train_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train['clean_tweet'] == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Another'] = df['Another'].replace('', np.nan)\n",
    "#replace all empty spaces with NaN to drop using dropna\n",
    "train['clean_tweet'] = train['clean_tweet'].replace('', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaasahan na ni Vice President Jejomar Binay n...</td>\n",
       "      <td>0</td>\n",
       "      <td>inaasahan na ni vice president jejomar binay n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...</td>\n",
       "      <td>1</td>\n",
       "      <td>mar roxas tang ina tuwid na daan daw    eh sya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "      <td>0</td>\n",
       "      <td>salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@rapplerdotcom putangina mo binay TAKBO PA</td>\n",
       "      <td>1</td>\n",
       "      <td>putangina mo binay takbo pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binay with selective amnesia, forgetting about...</td>\n",
       "      <td>0</td>\n",
       "      <td>binay with selective amnesia  forgetting about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>kaninang pa itong Binay binay binay.....tch</td>\n",
       "      <td>1</td>\n",
       "      <td>kaninang pa itong binay binay binay     tch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Mar Roxas on the rise, w/ momentum, machinery,...</td>\n",
       "      <td>0</td>\n",
       "      <td>mar roxas on the rise  w  momentum  machinery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Alan Cayetano 'confirms' Palace, Roxas, Poe be...</td>\n",
       "      <td>0</td>\n",
       "      <td>alan cayetano  confirms  palace  roxas  poe be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Mas nakakainis ad ni Mar kaysa kay Binay.</td>\n",
       "      <td>1</td>\n",
       "      <td>mas nakakainis ad ni mar kaysa kay binay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Preliminary and partial results coming in sugg...</td>\n",
       "      <td>0</td>\n",
       "      <td>preliminary and partial results coming in sugg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9506 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     Inaasahan na ni Vice President Jejomar Binay n...      0   \n",
       "1     Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...      1   \n",
       "2     Salamat sa walang sawang suporta ng mga taga m...      0   \n",
       "3            @rapplerdotcom putangina mo binay TAKBO PA      1   \n",
       "4     Binay with selective amnesia, forgetting about...      0   \n",
       "...                                                 ...    ...   \n",
       "9994        kaninang pa itong Binay binay binay.....tch      1   \n",
       "9995  Mar Roxas on the rise, w/ momentum, machinery,...      0   \n",
       "9997  Alan Cayetano 'confirms' Palace, Roxas, Poe be...      0   \n",
       "9998          Mas nakakainis ad ni Mar kaysa kay Binay.      1   \n",
       "9999  Preliminary and partial results coming in sugg...      0   \n",
       "\n",
       "                                            clean_tweet  \n",
       "0     inaasahan na ni vice president jejomar binay n...  \n",
       "1     mar roxas tang ina tuwid na daan daw    eh sya...  \n",
       "2     salamat sa walang sawang suporta ng mga taga m...  \n",
       "3                           putangina mo binay takbo pa  \n",
       "4     binay with selective amnesia  forgetting about...  \n",
       "...                                                 ...  \n",
       "9994        kaninang pa itong binay binay binay     tch  \n",
       "9995  mar roxas on the rise  w  momentum  machinery ...  \n",
       "9997  alan cayetano  confirms  palace  roxas  poe be...  \n",
       "9998          mas nakakainis ad ni mar kaysa kay binay   \n",
       "9999  preliminary and partial results coming in sugg...  \n",
       "\n",
       "[9506 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dropna(axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://statisticsglobe.com/drop-rows-blank-values-from-pandas-dataframe-python\n",
    "train['clean_tweet'] = train['clean_tweet'].replace('', float('NaN'), regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace= True)\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_column = train.pop('label')\n",
    "train.insert(0,'label',first_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9506, 3)\n"
     ]
    }
   ],
   "source": [
    "#total data entries for training\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5030"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for 0 values in train\n",
    "sum(train[\"label\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4476"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for 1 values in train\n",
    "sum(train[\"label\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distribution graph\n",
    "\n",
    "num_non_hate_speech = sum(train[\"label\"] == 0)\n",
    "num_hate_speech = sum(train[\"label\"] == 1)\n",
    "\n",
    "plt.bar([\"[0] Non-Hate Speech\", \"[1] Hate Speech\"], [num_non_hate_speech, num_hate_speech],\n",
    "        color=[\"blue\", \"orange\"])\n",
    "\n",
    "plt.title(\"Distribution of Hate Speech in Train Dataset\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Number of Occurrences\")\n",
    "\n",
    "for i, v in enumerate([num_non_hate_speech, num_hate_speech]):\n",
    "    plt.text(i, v+10, str(v), color='black', fontweight='bold', ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akin', 'aking', 'ako', 'alin', 'am', 'amin', 'aming', 'ang', 'ano', 'anumang', 'apat', 'at', 'atin', 'ating', 'ay', 'bababa', 'bago', 'bakit', 'bawat', 'bilang', 'dahil', 'dalawa', 'dapat', 'din', 'dito', 'doon', 'gagawin', 'gayunman', 'ginagawa', 'ginawa', 'ginawang', 'gumawa', 'gusto', 'habang', 'hanggang', 'hindi', 'huwag', 'iba', 'ibaba', 'ibabaw', 'ibig', 'ikaw', 'ilagay', 'ilalim', 'ilan', 'inyong', 'isa', 'isang', 'itaas', 'ito', 'iyo', 'iyon', 'iyong', 'ka', 'kahit', 'kailangan', 'kailanman', 'kami', 'kanila', 'kanilang', 'kanino', 'kanya', 'kanyang', 'kapag', 'kapwa', 'karamihan', 'katiyakan', 'katulad', 'kaya', 'kaysa', 'ko', 'kong', 'kulang', 'kumuha', 'kung', 'laban', 'lahat', 'lamang', 'likod', 'lima', 'maaari', 'maaaring', 'maging', 'mahusay', 'makita', 'marami', 'marapat', 'masyado', 'may', 'mayroon', 'mga', 'minsan', 'mismo', 'mula', 'muli', 'na', 'nabanggit', 'naging', 'nagkaroon', 'nais', 'nakita', 'namin', 'napaka', 'narito', 'nasaan', 'ng', 'ngayon', 'ni', 'nila', 'nilang', 'nito', 'niya', 'niyang', 'noon', 'o', 'pa', 'paano', 'pababa', 'paggawa', 'pagitan', 'pagkakaroon', 'pagkatapos', 'palabas', 'pamamagitan', 'panahon', 'pangalawa', 'para', 'paraan', 'pareho', 'pataas', 'pero', 'pumunta', 'pumupunta', 'sa', 'saan', 'sabi', 'sabihin', 'sarili', 'sila', 'sino', 'siya', 'tatlo', 'tayo', 'tulad', 'tungkol', 'una', 'walang']\n"
     ]
    }
   ],
   "source": [
    "#remove stopwords\n",
    "import urllib.request, json \n",
    "with urllib.request.urlopen(\"https://raw.githubusercontent.com/stopwords-iso/stopwords-tl/master/stopwords-tl.json\") as url:\n",
    "    stopwords = json.loads(url.read().decode())\n",
    "    print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['content2'] =data['Content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "train['rm_stpwrds'] = train['clean_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [inaasahan, vice, president, jejomar, binay, t...\n",
       "1    [mar, roxas, tang, ina, tuwid, daan, daw, eh, ...\n",
       "2    [salamat, sawang, suporta, taga, makati, pagba...\n",
       "3                        [putangina, mo, binay, takbo]\n",
       "4    [binay, with, selective, amnesia, forgetting, ...\n",
       "Name: tokenize, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization \n",
    "train['tokenize'] = train['rm_stpwrds'].apply(nltk.tokenize.WhitespaceTokenizer().tokenize) \n",
    "train['tokenize'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenize</th>\n",
       "      <th>lematize_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>[magpakatotoo, beh, corrupt, si, tatay, binay,...</td>\n",
       "      <td>[magpakatotoo, beh, corrupt, si, tatay, binay,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>[vp, not, immune, from, suit, says, cayetano]</td>\n",
       "      <td>[vp, not, immune, from, suit, say, cayetano]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>[leni, robredo, mar, roxas, stop, sakit, mata]</td>\n",
       "      <td>[leni, robredo, mar, roxas, stop, sakit, mata]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>[wag, n, yo, hayaan, maiwan, si, madame, leni,...</td>\n",
       "      <td>[wag, n, yo, hayaan, maiwan, si, madame, leni,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>[si, binay, nanunumbat, bwiset]</td>\n",
       "      <td>[si, binay, nanunumbat, bwiset]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tokenize  \\\n",
       "228   [magpakatotoo, beh, corrupt, si, tatay, binay,...   \n",
       "582       [vp, not, immune, from, suit, says, cayetano]   \n",
       "6287     [leni, robredo, mar, roxas, stop, sakit, mata]   \n",
       "5165  [wag, n, yo, hayaan, maiwan, si, madame, leni,...   \n",
       "6065                    [si, binay, nanunumbat, bwiset]   \n",
       "\n",
       "                                          lematize_nltk  \n",
       "228   [magpakatotoo, beh, corrupt, si, tatay, binay,...  \n",
       "582        [vp, not, immune, from, suit, say, cayetano]  \n",
       "6287     [leni, robredo, mar, roxas, stop, sakit, mata]  \n",
       "5165  [wag, n, yo, hayaan, maiwan, si, madame, leni,...  \n",
       "6065                    [si, binay, nanunumbat, bwiset]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lema_words(text):\n",
    "  wnl=WordNetLemmatizer()\n",
    "  return[wnl.lemmatize(w) for w in text]\n",
    "\n",
    "train['lematize_nltk']=train['tokenize'].apply(lema_words)  \n",
    "train[['tokenize','lematize_nltk']].sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceeding to Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tagalog stemmer\n",
    "\n",
    "VOWELS = \"aeiouAEIOU\"\n",
    "CONSONANTS = \"bcdfghklmnngpqrstvwyBCDFGHKLMNNGPQRSTVWY\"\n",
    "\n",
    "\"\"\" \n",
    "\tAffixes\n",
    "\"\"\"\n",
    "PREFIX_SET = [\n",
    "\t'nakikipag', 'pakikipag', 'pinakama', 'pagpapa', 'pinagka', 'panganga', 'makapag', 'nakapag', 'tagapag', 'makipag', 'nakipag', 'tigapag', 'pakiki', 'magpa', 'napaka', 'pinaka',\n",
    "\t'ipinag', 'pagka', 'pinag', 'mapag', 'mapa', 'taga', 'ipag', 'tiga', 'pala', 'pina', 'pang', 'naka', 'nang', 'mang', 'sing', 'ipa', 'pam', 'pan', 'pag', 'tag', 'mai', 'mag', 'nam',\n",
    "\t'nag', 'man', 'may', 'ma', 'na', 'ni', 'pa', 'ka', 'um', 'in', 'i',\n",
    "]\n",
    "\n",
    "INFIX_SET = [\n",
    "\t'um', 'in',\n",
    "]\n",
    "\n",
    "SUFFIX_SET = [\n",
    "\t'syon','dor', 'ita', 'han', 'hin', 'ing', 'ang', 'ng', 'an', 'in', 'g',\n",
    "]\n",
    "\n",
    "PERIOD_FLAG = True\n",
    "PASS_FLAG = False\n",
    "\n",
    "def check_vowel(substring):\n",
    "\t\"\"\"\n",
    "\t\tChecks if the substring is a vowel.\n",
    "\t\t\tletters: substring to be tested\n",
    "\t\treturns BOOLEAN\n",
    "\t\"\"\"\n",
    "\n",
    "\treturn all(letter in VOWELS for letter in substring)\n",
    "\n",
    "\n",
    "def check_consonant(substring):\n",
    "\t\"\"\"\n",
    "\t\tChecks if the letter is a consonant.\n",
    "\t\t\tletter: substring to be tested\n",
    "\t\treturns BOOLEAN\n",
    "\t\"\"\"\n",
    "\n",
    "\treturn all(letter in CONSONANTS for letter in substring)\n",
    "\n",
    "def change_letter(token, index, letter):\n",
    "\t\"\"\"\n",
    "\t\tReplaces a letter in a token.\n",
    "\t\t\ttoken: word to be used\n",
    "\t\t\tindex: index of the letter\n",
    "\t\t\tletter: letter used to replace\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t_list = list(token)\n",
    "\t_list[index] = letter\n",
    "\n",
    "\treturn ''.join(_list)\n",
    "\n",
    "def count_vowel(token):\n",
    "\t\"\"\"\n",
    "\t\tCount vowels in a given token.\n",
    "\t\t\ttoken: string to be counted for vowels\n",
    "\t\treturns INTEGER\n",
    "\t\"\"\"\n",
    "\n",
    "\tcount = 0\n",
    "\n",
    "\tfor tok in token:\n",
    "\t\tif check_vowel(tok):\n",
    "\t\t\tcount+=1\n",
    "\n",
    "\treturn count\n",
    "\n",
    "\n",
    "def count_consonant(token):\n",
    "\t\"\"\"\n",
    "\t\tCount consonants in a given token.\n",
    "\t\t\ttoken: string to be counted for consonants\n",
    "\t\treturns INTEGER\n",
    "\t\"\"\"\n",
    "\n",
    "\tcount = 0\n",
    "\n",
    "\tfor tok in token:\n",
    "\t\tif check_consonant(tok):\n",
    "\t\t\tcount+=1\n",
    "\n",
    "\treturn count\n",
    "\n",
    "\n",
    "def check_validation(token):\n",
    "    with open('stemmer/validation.txt', 'r') as valid:\n",
    "        data = valid.read().replace('\\n', ' ').split(' ')\n",
    "\n",
    "    return token in data\n",
    "\n",
    "\n",
    "def clean_repetition(token, REPETITION):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for repetition. (ex. nakakabaliw = nabaliw)\n",
    "\t\t\ttoken: word to be stemmed repetition\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tif len(token) >= 4:\n",
    "\t\tif check_vowel(token[0]):\n",
    "\t\t\tif token[0] == token[1]:\n",
    "\t\t\t\tREPETITION.append(token[0])\n",
    "\t\t\t\treturn token[1:]\n",
    "\n",
    "\t\telif check_consonant(token[0]) and count_vowel(token) >= 2:\n",
    "\t\t\tif token[0: 2] == token[2: 4] and len(token) - 2 >= 4:\n",
    "\t\t\t\tREPETITION.append(token[2:4])\n",
    "\t\t\t\treturn token[2:]\n",
    "\t\t\t\n",
    "\t\t\telif token[0: 3] == token[3: 6] and len(token) - 3 >= 4:\n",
    "\t\t\t\tREPETITION.append(token[3:6])\n",
    "\t\t\t\treturn token[3:]\n",
    "\n",
    "\treturn token\n",
    "\n",
    "def clean_suffix(token, SUFFIX):\n",
    "    \"\"\"\n",
    "    Checks token for suffixes. (ex. bigayan = bigay)\n",
    "        token: word to be stemmed for suffixes\n",
    "    returns STRING\n",
    "    \"\"\"\n",
    "\n",
    "    SUF_CANDIDATE = []\n",
    "\n",
    "    if check_validation(token):\n",
    "        return token\n",
    "\n",
    "    for suffix in SUFFIX_SET:\n",
    "        if len(token) - len(suffix) >= 3 and count_vowel(token[0:len(token) - len(suffix)]) >= 2 and count_consonant(token[0:len(token) - len(suffix)]) >= 1:\n",
    "            if token[len(token) - len(suffix): len(token)] == suffix:\n",
    "                if len(suffix) == 2 and not count_consonant(token[0:len(token) - len(suffix)]) >= 1:\n",
    "                    continue\n",
    "\n",
    "                if count_vowel(token[0: len(token) - len(suffix)]) >= 2:\n",
    "                    if suffix == 'ang' and check_consonant(token[-4]) \\\n",
    "                            and token[-4] != 'r' and token[-5] != 'u':\n",
    "                        continue\n",
    "\n",
    "                    #print(token[0: len(token) - len(suffix)] + \" : \" + suffix)\n",
    "\n",
    "                    if check_validation(token[0: len(token) - len(suffix)]):\n",
    "                        SUFFIX.append(suffix)\n",
    "                        return token[0: len(token) - len(suffix)] + 'a' if suffix == 'ita' \\\n",
    "                            else token[0: len(token) - len(suffix)]\n",
    "\n",
    "                    elif len(SUF_CANDIDATE) == 0:\n",
    "                        SUF_CANDIDATE.append(suffix)\n",
    "                        SUF_CANDIDATE.append(token[0: len(token) - len(suffix)])\n",
    "\n",
    "    if (len(SUF_CANDIDATE) == 2):\n",
    "        SUFFIX = SUF_CANDIDATE[0]\n",
    "        return SUF_CANDIDATE[1][0: len(token) - len(SUFFIX)] + 'a' if SUFFIX == 'ita' \\\n",
    "            else SUF_CANDIDATE[1][0: len(token) - len(SUFFIX)]\n",
    "\n",
    "    return token\n",
    "\n",
    "\n",
    "def clean_infix(token, INFIX):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for infixes. (ex. bumalik = balik)\n",
    "\t\t\ttoken: word to be stemmed for infixes\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tfor infix in INFIX_SET:\n",
    "\t\tif len(token) - len(infix) >= 3 and count_vowel(token[len(infix):]) >= 2:\n",
    "\t\t\tif token[0] == token[4] and token[1: 4] == infix:\n",
    "\t\t\t\tINFIX.append(infix)\n",
    "\t\t\t\treturn token[4:]\n",
    "\n",
    "\t\t\telif token[2] == token[4] and token[1: 3] == infix:\n",
    "\t\t\t\tINFIX.append(infix)\n",
    "\t\t\t\treturn token[0] + token[3:]\n",
    "\n",
    "\t\t\telif token[1: 3] == infix and check_vowel(token[3]):\n",
    "\t\t\t\tINFIX.append(infix)\n",
    "\t\t\t\treturn token[0] + token[3:]\n",
    "\n",
    "\treturn token\n",
    "\n",
    "\n",
    "def clean_prefix(token,\t PREFIX):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for prefixes. (ex. naligo = ligo)\n",
    "\t\t\ttoken: word to be stemmed for prefixes\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tfor prefix in PREFIX_SET:\n",
    "\t\tif len(token) - len(prefix) >= 3 and \\\n",
    "\t\t\tcount_vowel(token[len(prefix):]) >= 2:\n",
    "\n",
    "\t\t\tif prefix == ('i') and check_consonant(token[2]):\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif '-' in token:\t\n",
    "\t\t\t\ttoken = token.split('-')\n",
    "\n",
    "\t\t\t\tif token[0] == prefix and check_vowel(token[1][0]):\n",
    "\t\t\t\t\tPREFIX.append(prefix)\n",
    "\t\t\t\t\treturn token[1]\n",
    "\n",
    "\t\t\t\ttoken = '-'.join(token)\n",
    "\n",
    "\t\t\tif token[0: len(prefix)] == prefix:\n",
    "\t\t\t\tif count_vowel(token[len(prefix):]) >= 2:\n",
    "\n",
    "\t\t\t\t\tif prefix == 'panganga':\n",
    "\t\t\t\t\t\tPREFIX.append(prefix)\n",
    "\t\t\t\t\t\treturn 'ka' + token[len(prefix):]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tPREFIX.append(prefix)\n",
    "\t\t\t\t\treturn token[len(prefix):]\n",
    "\n",
    "\treturn token\n",
    "\n",
    "\n",
    "def clean_duplication(token, DUPLICATE):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for duplication. (ex. araw-araw = araw)\n",
    "\t\t\ttoken: word to be stemmed duplication\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tif '-' in token and token.index('-') != 0 and \\\n",
    "\t\ttoken.index('-') != len(token) -  1:\n",
    "\n",
    "\t\tsplit = token.split('-')\n",
    "\n",
    "\t\tif all(len(tok) >= 3 for tok in split):\n",
    "\t\t\tif split[0] == token[1] or split[0][-1] == 'u' and change_letter(split[0], -1, 'o') == split[1] or \\\n",
    "\t\t\t\tsplit[0][-2] == 'u' and change_letter(split[0], -2, 'o')  == split[1]:\n",
    "\t\t\t\tDUPLICATE.append(split[0])\n",
    "\t\t\t\treturn split[0]\n",
    "\n",
    "\t\t\telif split[0] == split[1][0:len(split[0])]:\n",
    "\t\t\t\tDUPLICATE.append(split[1])\n",
    "\t\t\t\treturn split[1]\n",
    "\n",
    "\t\t\telif split[0][-2:] == 'ng':\n",
    "\t\t\t\tif split[0][-3] == 'u':\n",
    "\t\t\t\t\tif split[0][0:-3] + 'o' == split[1]:\n",
    "\t\t\t\t\t\tDUPLICATE.append(split[1])\n",
    "\t\t\t\t\t\treturn split[1]\n",
    "\n",
    "\t\t\t\tif split[0][0:-2] == split[1]:\n",
    "\t\t\t\t\tDUPLICATE.append(split[1])\n",
    "\t\t\t\t\treturn split[1]\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn '-'.join(split)\n",
    "\t\n",
    "\treturn token\n",
    "\n",
    "\n",
    "def clean_repetition(token, REPETITION):\n",
    "\t\"\"\"\n",
    "\t\tChecks token for repetition. (ex. nakakabaliw = nabaliw)\n",
    "\t\t\ttoken: word to be stemmed repetition\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tif len(token) >= 4:\n",
    "\t\tif check_vowel(token[0]):\n",
    "\t\t\tif token[0] == token[1]:\n",
    "\t\t\t\tREPETITION.append(token[0])\n",
    "\t\t\t\treturn token[1:]\n",
    "\n",
    "\t\telif check_consonant(token[0]) and count_vowel(token) >= 2:\n",
    "\t\t\tif token[0: 2] == token[2: 4] and len(token) - 2 >= 4:\n",
    "\t\t\t\tREPETITION.append(token[2:4])\n",
    "\t\t\t\treturn token[2:]\n",
    "\t\t\t\n",
    "\t\t\telif token[0: 3] == token[3: 6] and len(token) - 3 >= 4:\n",
    "\t\t\t\tREPETITION.append(token[3:6])\n",
    "\t\t\t\treturn token[3:]\n",
    "\n",
    "\treturn token\n",
    "\n",
    "\n",
    "def clean_stemmed(token, CLEANERS, REPETITION):\n",
    "\t\t\n",
    "\tif not token:\n",
    "\t\treturn \"\"\n",
    "\t\n",
    "\t\"\"\"\n",
    "\t\tChecks for left-over affixes and letters.\n",
    "\t\t\ttoken: word to be cleaned for excess affixes/letters\n",
    "\t\treturns STRING\n",
    "\t\"\"\"\n",
    "\n",
    "\tglobal PERIOD_FLAG\n",
    "\tglobal PASS_FLAG\n",
    "\n",
    "\tCC_EXP = ['dr', 'gl', 'gr', 'ng', 'kr', 'kl', 'kw', 'ts', 'tr', 'pr', 'pl', 'pw', 'sw', 'sy'] # Consonant + Consonant Exceptions\n",
    "\n",
    "\tif token[-1] == '.' and PASS_FLAG == False:\n",
    "\t\tPERIOD_FLAG = True\n",
    "\n",
    "\tif not check_vowel(token[-1]) and not check_consonant(token[-1]):\n",
    "\t\tCLEANERS.append(token[-1])\n",
    "\t\ttoken = token[0:-1]\n",
    "\n",
    "\tif check_validation(token):\n",
    "\t\treturn token\n",
    "\n",
    "\tif len(token) >= 3 and count_vowel(token) >= 2:\n",
    "\t\ttoken = clean_repetition(token,\tREPETITION)\n",
    "\n",
    "\t\tif check_consonant(token[-1]) and token[- 2] == 'u':\n",
    "\t\t\tCLEANERS.append('u')\n",
    "\t\t\ttoken = change_letter(token, -2, 'o')\n",
    "\n",
    "\t\tif token[len(token) - 1] == 'u':\n",
    "\t\t\tCLEANERS.append('u')\n",
    "\t\t\ttoken = change_letter(token, -1, 'o')\n",
    "\n",
    "\t\tif token[-1] == 'r':\n",
    "\t\t\tCLEANERS.append('r')\n",
    "\t\t\ttoken = change_letter(token, -1, 'd')\n",
    "\n",
    "\t\tif token[-1] == 'h' and check_vowel(token[-1]):\n",
    "\t\t\tCLEANERS.append('h')\n",
    "\t\t\ttoken = token[0:-1]\n",
    "\n",
    "\t\tif token[0] == token[1]:\n",
    "\t\t\tCLEANERS.append(token[0])\n",
    "\t\t\ttoken = token[1:]\n",
    "\n",
    "\t\tif (token[0: 2] == 'ka' or token[0: 2] == 'pa') and check_consonant(token[2]) \\\n",
    "\t\t\tand count_vowel(token) >= 3:\n",
    "\t\t\t\n",
    "\t\t\tCLEANERS.append(token[0: 2])\n",
    "\t\t\ttoken = token[2:]\n",
    "\n",
    "\t\tif(token[-3:]) == 'han' and count_vowel(token[0:-3]) == 1:\n",
    "\t\t\tCLEANERS.append('han')\n",
    "\t\t\ttoken = token[0:-3] + 'i'\n",
    "\n",
    "\t\tif(token[-3:]) == 'han' and count_vowel(token[0:-3]) > 1:\n",
    "\t\t\tCLEANERS.append('han')\n",
    "\t\t\ttoken = token[0:-3]\n",
    "\n",
    "\t\tif len(token) >= 2 and count_vowel(token) >= 3:\n",
    "\t\t\tif token[-1] == 'h' and check_vowel(token[-2]):\n",
    "\t\t\t\tCLEANERS.append('h')\n",
    "\t\t\t\ttoken = token[0:-1]\n",
    "\n",
    "\t\tif len(token) >= 6 and token[0:2] == token[2:4]:\n",
    "\t\t\tCLEANERS.append('0:2')\n",
    "\t\t\ttoken = token[2:]\n",
    "\n",
    "\t\tif any(REP[0] == 'r' for REP in REPETITION):\n",
    "\t\t\tCLEANERS.append('r')\n",
    "\t\t\ttoken = change_letter(token, 0, 'd')\n",
    "\n",
    "\t\tif token[-2:] == 'ng' and token[-3] == 'u':\n",
    "\t\t\tCLEANERS.append('u')\n",
    "\t\t\ttoken = change_letter(token, -3, 'o')\n",
    "\n",
    "\t\tif token[-1] == 'h':\n",
    "\t\t\tCLEANERS.append('h')\n",
    "\t\t\ttoken = token[0:-1]\n",
    "\n",
    "\t\tif any(token[0:2] != CC for CC in CC_EXP) and check_consonant(token[0:2]):\n",
    "\t\t\tCLEANERS.append(token[0:2])\n",
    "\t\t\ttoken = token[1:]\n",
    "\n",
    "\treturn token\n",
    "\n",
    "\n",
    "def tg_stemmer(tokens):\n",
    "\n",
    "    global PERIOD_FLAG\n",
    "    global PASS_FLAG\n",
    "\n",
    "    pre_stem     = inf_stem = suf_stem = rep_stem = \\\n",
    "        du1_stem = du2_stem = cle_stem = '-'\n",
    "    word_info    = {}\n",
    "    PREFIX     = []\n",
    "    INFIX      = []\n",
    "    SUFFIX     = []\n",
    "    DUPLICATE  = []\n",
    "    REPETITION = []\n",
    "    CLEANERS   = []\n",
    "\n",
    "    word_info['clean'] = '-'\n",
    "    stemmed_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        word_info = {}\n",
    "        word_info[\"word\"] = token\n",
    "\n",
    "        if (PERIOD_FLAG == True and token[0].isupper()) or \\\n",
    "                (PERIOD_FLAG == False and token[0].islower()):\n",
    "            token = token.lower()\n",
    "            du1_stem = clean_duplication(token, DUPLICATE)\n",
    "            pre_stem = clean_prefix(du1_stem, PREFIX)\n",
    "            rep_stem = clean_repetition(pre_stem, REPETITION)\n",
    "            inf_stem = clean_infix(rep_stem, INFIX)\n",
    "            rep_stem = clean_repetition(inf_stem, REPETITION)\n",
    "            suf_stem = clean_suffix(rep_stem, SUFFIX)\n",
    "            du2_stem = clean_duplication(suf_stem, DUPLICATE)\n",
    "            cle_stem = clean_stemmed(du2_stem, CLEANERS, REPETITION)\n",
    "            cle_stem = clean_duplication(cle_stem, DUPLICATE)\n",
    "\n",
    "            if '-' in cle_stem:\n",
    "                cle_stem.replace('-', '')\n",
    "\n",
    "        else:\n",
    "            PERIOD_FLAG = False\n",
    "            cle_stem = clean_stemmed(token, CLEANERS, REPETITION)\n",
    "            word_info[\"root\"]   = token\n",
    "            word_info[\"prefix\"] = '[]'\n",
    "            word_info[\"infix\"]  = '[]'\n",
    "            word_info[\"suffix\"] = '[]'\n",
    "            word_info[\"repeat\"] = '[]'\n",
    "            word_info[\"dupli\"]  = '[]'\n",
    "            word_info[\"clean\"]  = cle_stem\n",
    "\n",
    "        stemmed_tokens.append(cle_stem)\n",
    "\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#english lemmatizer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def english_lemmatizer(token):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jmest\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing resources results here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU usage at start: 3.1%\n",
      "Memory usage at start: 296.3828125 MB\n",
      "CPU usage at end: 6.8%\n",
      "Memory usage at end: 418.0703125 MB\n"
     ]
    }
   ],
   "source": [
    "#language detection > stem/lemmatize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tagalog_english(tokens):\n",
    "    lemmatized_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if wordnet.synsets(token):\n",
    "            pos = nltk.pos_tag([token])[0][1][0].lower()\n",
    "            pos = {'a': wordnet.ADJ,\n",
    "                   'n': wordnet.NOUN,\n",
    "                   'v': wordnet.VERB,\n",
    "                   'r': wordnet.ADV}.get(pos, wordnet.NOUN)\n",
    "            lemmatized_token = lemmatizer.lemmatize(token, pos)\n",
    "        else:\n",
    "            lemmatized_token = tg_stemmer([token])[0]\n",
    "        \n",
    "        lemmatized_tokens.append(lemmatized_token)\n",
    "\n",
    "    return lemmatized_tokens\n",
    "\n",
    "\n",
    "process = psutil.Process()\n",
    "memory_info_start = process.memory_info().rss\n",
    "cpu_percent_start = psutil.cpu_percent()\n",
    "print(f\"CPU usage at start: {cpu_percent_start}%\")\n",
    "print(f\"Memory usage at start: {memory_info_start / 1024 / 1024} MB\")\n",
    "\n",
    "train['lemmatize'] = train['tokenize'].apply(lemmatize_tagalog_english)\n",
    "\n",
    "cpu_percent_end = psutil.cpu_percent()\n",
    "memory_info_end = process.memory_info().rss\n",
    "print(f\"CPU usage at end: {cpu_percent_end}%\")\n",
    "print(f\"Memory usage at end: {memory_info_end / 1024 / 1024} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>rm_stpwrds</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>1</td>\n",
       "      <td>The desperate move of Roxas to ask Poe to \"uni...</td>\n",
       "      <td>the desperate move of roxas to ask poe to unit...</td>\n",
       "      <td>[the, desperate, move, of, roxas, to, ask, poe...</td>\n",
       "      <td>[the, desperate, move, of, roxas, to, ask, poe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>1</td>\n",
       "      <td>After Sinulog, kani na sad.. binay ikaw na.. a...</td>\n",
       "      <td>after sinulog kani sad binay pinakamakapal</td>\n",
       "      <td>[after, sinulog, kani, sad, binay, pinakamakapal]</td>\n",
       "      <td>[after, sulo, kani, sad, binay, kapal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>1</td>\n",
       "      <td>Wag na wag ko lang malalaman na buhay ni Mar R...</td>\n",
       "      <td>wag wag lang malalaman buhay mar roxas susunod...</td>\n",
       "      <td>[wag, wag, lang, malalaman, buhay, mar, roxas,...</td>\n",
       "      <td>[wag, wag, lang, laman, buhay, mar, roxas, sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>0</td>\n",
       "      <td>Kung di man si duterte, Miriam nalang presiden...</td>\n",
       "      <td>di man si duterte miriam nalang president mar ...</td>\n",
       "      <td>[di, man, si, duterte, miriam, nalang, preside...</td>\n",
       "      <td>[di, man, si, duterte, miriam, nala, president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9500</th>\n",
       "      <td>0</td>\n",
       "      <td>You can't make me watch Delta aaaaaaaaaaaaaaaaa</td>\n",
       "      <td>you can t make me watch delta aaaaaaaaaaaaaaaaa</td>\n",
       "      <td>[you, can, t, make, me, watch, delta, aaaaaaaa...</td>\n",
       "      <td>[yoo, can, t, make, me, watch, delta, aaaaaaaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9501</th>\n",
       "      <td>1</td>\n",
       "      <td>kaninang pa itong Binay binay binay.....tch</td>\n",
       "      <td>kaninang itong binay binay binay tch</td>\n",
       "      <td>[kaninang, itong, binay, binay, binay, tch]</td>\n",
       "      <td>[nina, ito, binay, binay, binay, tch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9502</th>\n",
       "      <td>0</td>\n",
       "      <td>Mar Roxas on the rise, w/ momentum, machinery,...</td>\n",
       "      <td>mar roxas on the rise w momentum machinery gra...</td>\n",
       "      <td>[mar, roxas, on, the, rise, w, momentum, machi...</td>\n",
       "      <td>[mar, roxas, on, the, rise, w, momentum, machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9503</th>\n",
       "      <td>0</td>\n",
       "      <td>Alan Cayetano 'confirms' Palace, Roxas, Poe be...</td>\n",
       "      <td>alan cayetano confirms palace roxas poe behind...</td>\n",
       "      <td>[alan, cayetano, confirms, palace, roxas, poe,...</td>\n",
       "      <td>[alan, cayetano, confirms, palace, roxas, poe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9504</th>\n",
       "      <td>1</td>\n",
       "      <td>Mas nakakainis ad ni Mar kaysa kay Binay.</td>\n",
       "      <td>mas nakakainis ad mar kay binay</td>\n",
       "      <td>[mas, nakakainis, ad, mar, kay, binay]</td>\n",
       "      <td>[ma, kainis, ad, mar, kay, binay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9505</th>\n",
       "      <td>0</td>\n",
       "      <td>Preliminary and partial results coming in sugg...</td>\n",
       "      <td>preliminary and partial results coming in sugg...</td>\n",
       "      <td>[preliminary, and, partial, results, coming, i...</td>\n",
       "      <td>[preliminary, and, partial, result, come, in, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "9496      1  The desperate move of Roxas to ask Poe to \"uni...   \n",
       "9497      1  After Sinulog, kani na sad.. binay ikaw na.. a...   \n",
       "9498      1  Wag na wag ko lang malalaman na buhay ni Mar R...   \n",
       "9499      0  Kung di man si duterte, Miriam nalang presiden...   \n",
       "9500      0    You can't make me watch Delta aaaaaaaaaaaaaaaaa   \n",
       "9501      1        kaninang pa itong Binay binay binay.....tch   \n",
       "9502      0  Mar Roxas on the rise, w/ momentum, machinery,...   \n",
       "9503      0  Alan Cayetano 'confirms' Palace, Roxas, Poe be...   \n",
       "9504      1          Mas nakakainis ad ni Mar kaysa kay Binay.   \n",
       "9505      0  Preliminary and partial results coming in sugg...   \n",
       "\n",
       "                                             rm_stpwrds  \\\n",
       "9496  the desperate move of roxas to ask poe to unit...   \n",
       "9497         after sinulog kani sad binay pinakamakapal   \n",
       "9498  wag wag lang malalaman buhay mar roxas susunod...   \n",
       "9499  di man si duterte miriam nalang president mar ...   \n",
       "9500    you can t make me watch delta aaaaaaaaaaaaaaaaa   \n",
       "9501               kaninang itong binay binay binay tch   \n",
       "9502  mar roxas on the rise w momentum machinery gra...   \n",
       "9503  alan cayetano confirms palace roxas poe behind...   \n",
       "9504                    mas nakakainis ad mar kay binay   \n",
       "9505  preliminary and partial results coming in sugg...   \n",
       "\n",
       "                                               tokenize  \\\n",
       "9496  [the, desperate, move, of, roxas, to, ask, poe...   \n",
       "9497  [after, sinulog, kani, sad, binay, pinakamakapal]   \n",
       "9498  [wag, wag, lang, malalaman, buhay, mar, roxas,...   \n",
       "9499  [di, man, si, duterte, miriam, nalang, preside...   \n",
       "9500  [you, can, t, make, me, watch, delta, aaaaaaaa...   \n",
       "9501        [kaninang, itong, binay, binay, binay, tch]   \n",
       "9502  [mar, roxas, on, the, rise, w, momentum, machi...   \n",
       "9503  [alan, cayetano, confirms, palace, roxas, poe,...   \n",
       "9504             [mas, nakakainis, ad, mar, kay, binay]   \n",
       "9505  [preliminary, and, partial, results, coming, i...   \n",
       "\n",
       "                                              lemmatize  \n",
       "9496  [the, desperate, move, of, roxas, to, ask, poe...  \n",
       "9497             [after, sulo, kani, sad, binay, kapal]  \n",
       "9498  [wag, wag, lang, laman, buhay, mar, roxas, sun...  \n",
       "9499  [di, man, si, duterte, miriam, nala, president...  \n",
       "9500  [yoo, can, t, make, me, watch, delta, aaaaaaaa...  \n",
       "9501              [nina, ito, binay, binay, binay, tch]  \n",
       "9502  [mar, roxas, on, the, rise, w, momentum, machi...  \n",
       "9503  [alan, cayetano, confirms, palace, roxas, poe,...  \n",
       "9504                  [ma, kainis, ad, mar, kay, binay]  \n",
       "9505  [preliminary, and, partial, result, come, in, ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview\n",
    "train[['label','text','rm_stpwrds','tokenize','lemmatize']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(train['lemmatize'], train['label'], test_size=0.3, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(map(' '.join, X_train))\n",
    "X_test = vectorizer.transform(map(' '.join, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm training\n",
    "\n",
    "param_grid = {'C': [10], 'gamma': [0.1]}\n",
    "\n",
    "svm_model = SVC(kernel='sigmoid')\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "svm_model = SVC(kernel='sigmoid', C=best_params['C'], gamma=best_params['gamma'], probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "y_train_pred = svm_model.predict(X_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Resources Results here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU usage at start: 2.8%\n",
      "Memory usage at start: 93.60546875 MB\n",
      "CPU usage at end: 7.5%\n",
      "Memory usage at end: 91.125 MB\n"
     ]
    }
   ],
   "source": [
    "#train resource analytics\n",
    "def train_svm():\n",
    "    param_grid = {'C': [10], 'gamma': [0.1]}\n",
    "\n",
    "    svm_model = SVC(kernel='sigmoid')\n",
    "\n",
    "    grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    svm_model = SVC(kernel='sigmoid', C=best_params['C'], gamma=best_params['gamma'])\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    joblib.dump(svm_model, 'svm_model.joblib')\n",
    "    joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "    process = psutil.Process()\n",
    "    memory_info_start = process.memory_info().rss\n",
    "    cpu_percent_start = psutil.cpu_percent()\n",
    "    print(f\"CPU usage at start: {cpu_percent_start}%\")\n",
    "    print(f\"Memory usage at start: {memory_info_start / 1024 / 1024} MB\")\n",
    "\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_train_pred = svm_model.predict(X_train)\n",
    "\n",
    "    # accuracy = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    # print(\"Training Data Accuracy using metrics.accuracy_score():\", accuracy)\n",
    "\n",
    "    # accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    # print(\"Test Data Accuracy using metrics.accuracy_score():\", accuracy)\n",
    "\n",
    "    cpu_percent_end = psutil.cpu_percent()\n",
    "    memory_info_end = process.memory_info().rss\n",
    "    print(f\"CPU usage at end: {cpu_percent_end}%\")\n",
    "    print(f\"Memory usage at end: {memory_info_end / 1024 / 1024} MB\")\n",
    "    \n",
    "train_svm()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #precision-recall curve\n",
    "\n",
    "# precision, recall, thresholds = precision_recall_curve(y_test, svm_model.decision_function(X_test))\n",
    "# area = auc(recall, precision)\n",
    "\n",
    "# plt.plot(recall, precision, label=f'Precision-Recall curve (AUC = {area:.2f})')\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.title(f'Precision-Recall Curve (AUC = {area:.2f})')\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ROC curve\n",
    "\n",
    "# y_pred_prob = svm_model.predict_proba(X_test)[:, 1]\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# print(\"Area Under the ROC Curve (AUC): \", roc_auc)\n",
    "\n",
    "# plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"confusion_matrix:\")\n",
    "# LABEL=['0','1']\n",
    "# conf=confusion_matrix(y_test,y_pred)\n",
    "# fig, ax = plot_confusion_matrix(conf_mat=conf,\n",
    "#                                 show_absolute=True,\n",
    "#                                 show_normed=True,\n",
    "#                                 colorbar=True)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"\\nClassification Report of SVM Classifier:\\n\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Kernel analysis\n",
    "\n",
    "# models = ['Polynomial', 'Rbf', 'Sigmoid', 'One-vs-Rest']\n",
    "# train_accuracies = [0.9781693845344556, 0.9643608627038401, 0.8917944093778178, 0.9643608627038401]\n",
    "# test_accuracies = [0.7560462670872765, 0.7607781282860148, 0.7370266479663394, 0.7607781282860148]\n",
    "# diff_accuracies = [train_accuracies[i] - test_accuracies[i] for i in range(len(models))]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# x = range(len(models))\n",
    "# width = 0.35\n",
    "# ax.bar([i - width/2 for i in x], train_accuracies, width, label='Training Data')\n",
    "# ax.bar([i + width/2 for i in x], test_accuracies, width, label='Test Data')\n",
    "# ax.bar(x, diff_accuracies, width, bottom=test_accuracies, color='red', alpha=0.5, label='Difference')\n",
    "# ax.set_ylim(0.6, 1)\n",
    "# ax.set_ylabel('Accuracy')\n",
    "# ax.set_title('SVM Models and Their Accuracies')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(models)\n",
    "# ax.legend()\n",
    "\n",
    "# for i, diff in enumerate(diff_accuracies):\n",
    "#     ax.text(i, test_accuracies[i] + diff/2, f'{round(diff, 2)}', ha='center', va='bottom')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource utilization graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc_names = ['PC 1', 'PC 2', 'PC 3']\n",
    "# time_spent = [6*60 + 22.8, 9*60 + 42, 8*60 + 25.0]\n",
    "\n",
    "# # plot\n",
    "# plt.bar(pc_names, time_spent)\n",
    "\n",
    "# # add labels\n",
    "# for i, v in enumerate(time_spent):\n",
    "#     plt.text(i, v+5, f\"{v:.1f}s\", ha='center', fontweight='bold')\n",
    "\n",
    "# # axes labels and title\n",
    "# plt.xlabel('PC')\n",
    "# plt.ylabel('Time spent in preprocessing (seconds)')\n",
    "# plt.title('Time spent in preprocessing on different PCs')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc_names = ['PC 1', 'PC 2', 'PC 3']\n",
    "# time_spent = [25.5, 35.7, 29.2]\n",
    "\n",
    "# plt.bar(pc_names, time_spent)\n",
    "\n",
    "# for i, v in enumerate(time_spent):\n",
    "#     plt.text(i, v/2, f\"{v:.1f}s\", ha='center', fontweight='bold')\n",
    "\n",
    "# plt.xlabel('PC')\n",
    "# plt.ylabel('Time spent in training (seconds)')\n",
    "# plt.title('Time spent in training on different PCs')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_usage = [7.4, 14.2, 35.2]\n",
    "# end_usage = [10.1, 45.4, 30.8]\n",
    "# labels = ['PC 1', 'PC 2', 'PC 3']\n",
    "\n",
    "# x = np.arange(len(labels))\n",
    "# width = 0.35\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# rects1 = ax.bar(x - width/2, start_usage, width, label='Start')\n",
    "# rects2 = ax.bar(x + width/2, end_usage, width, label='End')\n",
    "\n",
    "# ax.set_ylabel('CPU usage (%)')\n",
    "# ax.set_title('CPU usage for preprocessing')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend()\n",
    "\n",
    "# def autolabel(rects):\n",
    "#     for rect in rects:\n",
    "#         height = rect.get_height()\n",
    "#         ax.annotate('{:.1f}'.format(height),\n",
    "#                     xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                     xytext=(0, 3),\n",
    "#                     textcoords=\"offset points\",\n",
    "#                     ha='center', va='bottom')\n",
    "\n",
    "# autolabel(rects1)\n",
    "# autolabel(rects2)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_usage = [7.9, 27.2, 36]\n",
    "# end_usage = [7.2, 25.3, 32.7]\n",
    "# labels = ['PC 1', 'PC 2', 'PC 3']\n",
    "\n",
    "# x = np.arange(len(labels))\n",
    "# width = 0.35\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# rects1 = ax.bar(x - width/2, start_usage, width, label='Start')\n",
    "# rects2 = ax.bar(x + width/2, end_usage, width, label='End')\n",
    "\n",
    "# ax.set_ylabel('CPU usage (%)')\n",
    "# ax.set_title('CPU usage for training')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend()\n",
    "\n",
    "# def autolabel(rects):\n",
    "#     for rect in rects:\n",
    "#         height = rect.get_height()\n",
    "#         ax.annotate('{:.1f}'.format(height),\n",
    "#                     xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                     xytext=(0, 3),\n",
    "#                     textcoords=\"offset points\",\n",
    "#                     ha='center', va='bottom')\n",
    "\n",
    "# autolabel(rects1)\n",
    "# autolabel(rects2)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_mem_usage = [289.754, 231.94921875, 290.105]\n",
    "# end_mem_usage = [412.098, 417.73828125, 409.027]\n",
    "# labels = ['PC 1', 'PC 2', 'PC 3']\n",
    "\n",
    "# x = np.arange(len(labels))\n",
    "# width = 0.35\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# rects1 = ax.bar(x - width/2, start_mem_usage, width, label='Start')\n",
    "# rects2 = ax.bar(x + width/2, end_mem_usage, width, label='End')\n",
    "\n",
    "# ax.set_ylabel('Memory usage (MB)')\n",
    "# ax.set_title('Memory usage for preprocessing')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "\n",
    "# def autolabel(rects):\n",
    "#     for rect in rects:\n",
    "#         height = rect.get_height()\n",
    "#         ax.annotate('{:.1f}'.format(height),\n",
    "#                     xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                     xytext=(0, 3),\n",
    "#                     textcoords=\"offset points\",\n",
    "#                     ha='center', va='bottom')\n",
    "\n",
    "# autolabel(rects1)\n",
    "# autolabel(rects2)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_mem_usage = [425.781, 431.789, 438.727]\n",
    "# end_mem_usage = [422.734, 428.582, 438.727]\n",
    "# labels = ['PC 1', 'PC 2', 'PC 3']\n",
    "\n",
    "# x = np.arange(len(labels))\n",
    "# width = 0.35\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# rects1 = ax.bar(x - width/2, start_mem_usage, width, label='Start')\n",
    "# rects2 = ax.bar(x + width/2, end_mem_usage, width, label='End')\n",
    "# ax.set_ylabel('Memory usage (MB)')\n",
    "# ax.set_title('Memory usage for training')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "\n",
    "# def autolabel(rects):\n",
    "#     for rect in rects:\n",
    "#         height = rect.get_height()\n",
    "#         ax.annotate('{:.1f}'.format(height),\n",
    "#                     xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                     xytext=(0, 3),\n",
    "#                     textcoords=\"offset points\",\n",
    "#                     ha='center', va='bottom')\n",
    "\n",
    "# autolabel(rects1)\n",
    "# autolabel(rects2)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Input proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO \n",
      "Positive Sentiment\n"
     ]
    }
   ],
   "source": [
    "# Download Filipino stopwords\n",
    "with urllib.request.urlopen(\"https://raw.githubusercontent.com/stopwords-iso/stopwords-tl/master/stopwords-tl.json\") as url:\n",
    "    stopwords_tl = json.loads(url.read().decode())\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove unwanted characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    #Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Convert tokens to lowercase\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # # Remove stopwords\n",
    "    tokens = [word for word in tokens if word.lower() not in stopwords_tl]\n",
    "    # Lemmatize the tokens\n",
    "    lemmatized_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if wordnet.synsets(token):\n",
    "            pos = nltk.pos_tag([token])[0][1][0].lower()\n",
    "            pos = {'a': wordnet.ADJ,\n",
    "                   'n': wordnet.NOUN,\n",
    "                   'v': wordnet.VERB,\n",
    "                   'r': wordnet.ADV}.get(pos, wordnet.NOUN)\n",
    "            lemmatized_token = lemmatizer.lemmatize(token, pos)\n",
    "        else:\n",
    "            lemmatized_token = tg_stemmer([token])[0]\n",
    "        \n",
    "        lemmatized_tokens.append(lemmatized_token)\n",
    "        \n",
    "    # Join the tokens back into a string\n",
    "    text = ' '.join(lemmatized_tokens)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Load the trained SVM model\n",
    "clf = joblib.load('svm_model.joblib')\n",
    "\n",
    "# Load the vectorizer fitted on the training data\n",
    "vectorizer = joblib.load('tfidf_vectorizer.joblib')\n",
    "\n",
    "# Get input from user\n",
    "sentiment = input(\"Enter a sentence to analyze: \")\n",
    "\n",
    "# Preprocess the input text\n",
    "sentiment_processed = preprocess_text(sentiment)\n",
    "\n",
    "# Vectorize the input text\n",
    "sentiment_vectorized = vectorizer.transform([sentiment_processed])\n",
    "\n",
    "# Predict the sentiment using the trained SVM model\n",
    "prediction = clf.predict(sentiment_vectorized)\n",
    "\n",
    "print(sentiment)\n",
    "# Print the prediction\n",
    "if prediction == 1:\n",
    "    print(\"Negative Sentiment\")\n",
    "else:\n",
    "    print(\"Positive Sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
