{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary dependencies\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "train = pd.read_csv(r\"C:\\Users\\Admin\\OneDrive\\Documents\\Webdev\\hatespeech\\train.csv\", nrows=5000)\n",
    "\n",
    "#testing data\n",
    "test = pd.read_csv(r\"C:\\Users\\Admin\\OneDrive\\Documents\\Webdev\\hatespeech\\test.csv\", nrows=5000)\n",
    "\n",
    "\n",
    "# # #training data\n",
    "# train = pd.read_csv(r\"C:\\Users\\jmest\\Documents\\Files\\C4S2\\Thesis\\ThesisFiles-main\\ThesisFiles-main\\hatespeech\\train.csv\", nrows=5000)\n",
    "\n",
    "# # #testing data\n",
    "# test = pd.read_csv(r\"C:\\Users\\jmest\\Documents\\Files\\C4S2\\Thesis\\ThesisFiles-main\\ThesisFiles-main\\hatespeech\\test.csv\", nrows=5000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaasahan na ni Vice President Jejomar Binay n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@rapplerdotcom putangina mo binay TAKBO PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binay with selective amnesia, forgetting about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Awww DUTERTE Na wag Lang si Roxas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>RT @mikkieugenio: If the SC disqualifies Poe a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>\"Pag naging presidente si Binay, wala kayong t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Yan na naman ang walang kwentang commercial ni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>https://t.co/CeNBKhrm8P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Inaasahan na ni Vice President Jejomar Binay n...      0\n",
       "1     Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...      1\n",
       "2     Salamat sa walang sawang suporta ng mga taga m...      0\n",
       "3            @rapplerdotcom putangina mo binay TAKBO PA      1\n",
       "4     Binay with selective amnesia, forgetting about...      0\n",
       "...                                                 ...    ...\n",
       "4995                  Awww DUTERTE Na wag Lang si Roxas      0\n",
       "4996  RT @mikkieugenio: If the SC disqualifies Poe a...      0\n",
       "4997  \"Pag naging presidente si Binay, wala kayong t...      0\n",
       "4998  Yan na naman ang walang kwentang commercial ni...      1\n",
       "4999                            https://t.co/CeNBKhrm8P      0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with null values\n",
    "train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values in train\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for 0 values in train\n",
    "sum(train[\"label\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2347"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for 1 values in train\n",
    "sum(train[\"label\"] == 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data of unwated Text and Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters using the regular expression library\n",
    "\n",
    "import re\n",
    "\n",
    "#set up punctuations we want to be replaced\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "\n",
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean training data\n",
    "train_tweet = clean_tweets(train[\"text\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaasahan na ni Vice President Jejomar Binay n...</td>\n",
       "      <td>0</td>\n",
       "      <td>inaasahan na ni vice president jejomar binay n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...</td>\n",
       "      <td>1</td>\n",
       "      <td>mar roxas tang ina tuwid na daan daw  eh sya n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "      <td>0</td>\n",
       "      <td>salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@rapplerdotcom putangina mo binay TAKBO PA</td>\n",
       "      <td>1</td>\n",
       "      <td>putangina mo binay takbo pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binay with selective amnesia, forgetting about...</td>\n",
       "      <td>0</td>\n",
       "      <td>binay with selective amnesia forgetting about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It doesn't matter whoever won between Duterte ...</td>\n",
       "      <td>0</td>\n",
       "      <td>it doesnt matter whoever won between duterte &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nognog? Pero nognog din ang nag malasakit? Wtf...</td>\n",
       "      <td>1</td>\n",
       "      <td>nognog pero nognog din ang nag malasakit wtf t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#OnlyB1nay ?? #FB https://t.co/QEQnsK67Gm</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What Abi Binay said on running for Makati mayo...</td>\n",
       "      <td>0</td>\n",
       "      <td>what abi binay said on running for makati mayor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Srsly. How can Binay do away with no tax for t...</td>\n",
       "      <td>1</td>\n",
       "      <td>srsly how can binay do away with no tax for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label   \n",
       "0  Inaasahan na ni Vice President Jejomar Binay n...      0  \\\n",
       "1  Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...      1   \n",
       "2  Salamat sa walang sawang suporta ng mga taga m...      0   \n",
       "3         @rapplerdotcom putangina mo binay TAKBO PA      1   \n",
       "4  Binay with selective amnesia, forgetting about...      0   \n",
       "5  It doesn't matter whoever won between Duterte ...      0   \n",
       "6  Nognog? Pero nognog din ang nag malasakit? Wtf...      1   \n",
       "7          #OnlyB1nay ?? #FB https://t.co/QEQnsK67Gm      1   \n",
       "8  What Abi Binay said on running for Makati mayo...      0   \n",
       "9  Srsly. How can Binay do away with no tax for t...      1   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  inaasahan na ni vice president jejomar binay n...  \n",
       "1  mar roxas tang ina tuwid na daan daw  eh sya n...  \n",
       "2  salamat sa walang sawang suporta ng mga taga m...  \n",
       "3                        putangina mo binay takbo pa  \n",
       "4  binay with selective amnesia forgetting about ...  \n",
       "5  it doesnt matter whoever won between duterte &...  \n",
       "6  nognog pero nognog din ang nag malasakit wtf t...  \n",
       "7                                                     \n",
       "8    what abi binay said on running for makati mayor  \n",
       "9  srsly how can binay do away with no tax for th...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append cleaned tweets to the training data\n",
    "train[\"clean_tweet\"] = train_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train['clean_tweet'] == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Another'] = df['Another'].replace('', np.nan)\n",
    "#replace all empty spaces with NaN to drop using dropna\n",
    "train['clean_tweet'] = train['clean_tweet'].replace('', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaasahan na ni Vice President Jejomar Binay n...</td>\n",
       "      <td>0</td>\n",
       "      <td>inaasahan na ni vice president jejomar binay n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...</td>\n",
       "      <td>1</td>\n",
       "      <td>mar roxas tang ina tuwid na daan daw  eh sya n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "      <td>0</td>\n",
       "      <td>salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@rapplerdotcom putangina mo binay TAKBO PA</td>\n",
       "      <td>1</td>\n",
       "      <td>putangina mo binay takbo pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binay with selective amnesia, forgetting about...</td>\n",
       "      <td>0</td>\n",
       "      <td>binay with selective amnesia forgetting about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It doesn't matter whoever won between Duterte ...</td>\n",
       "      <td>0</td>\n",
       "      <td>it doesnt matter whoever won between duterte &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nognog? Pero nognog din ang nag malasakit? Wtf...</td>\n",
       "      <td>1</td>\n",
       "      <td>nognog pero nognog din ang nag malasakit wtf t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What Abi Binay said on running for Makati mayo...</td>\n",
       "      <td>0</td>\n",
       "      <td>what abi binay said on running for makati mayor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Srsly. How can Binay do away with no tax for t...</td>\n",
       "      <td>1</td>\n",
       "      <td>srsly how can binay do away with no tax for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sen Grace Poe, puro ka puso. Kaya lugmok bansa...</td>\n",
       "      <td>1</td>\n",
       "      <td>sen grace poe puro ka puso kaya lugmok bansa n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label   \n",
       "0   Inaasahan na ni Vice President Jejomar Binay n...      0  \\\n",
       "1   Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...      1   \n",
       "2   Salamat sa walang sawang suporta ng mga taga m...      0   \n",
       "3          @rapplerdotcom putangina mo binay TAKBO PA      1   \n",
       "4   Binay with selective amnesia, forgetting about...      0   \n",
       "5   It doesn't matter whoever won between Duterte ...      0   \n",
       "6   Nognog? Pero nognog din ang nag malasakit? Wtf...      1   \n",
       "8   What Abi Binay said on running for Makati mayo...      0   \n",
       "9   Srsly. How can Binay do away with no tax for t...      1   \n",
       "10  Sen Grace Poe, puro ka puso. Kaya lugmok bansa...      1   \n",
       "\n",
       "                                          clean_tweet  \n",
       "0   inaasahan na ni vice president jejomar binay n...  \n",
       "1   mar roxas tang ina tuwid na daan daw  eh sya n...  \n",
       "2   salamat sa walang sawang suporta ng mga taga m...  \n",
       "3                         putangina mo binay takbo pa  \n",
       "4   binay with selective amnesia forgetting about ...  \n",
       "5   it doesnt matter whoever won between duterte &...  \n",
       "6   nognog pero nognog din ang nag malasakit wtf t...  \n",
       "8     what abi binay said on running for makati mayor  \n",
       "9   srsly how can binay do away with no tax for th...  \n",
       "10  sen grace poe puro ka puso kaya lugmok bansa n...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dropna(axis='rows').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://statisticsglobe.com/drop-rows-blank-values-from-pandas-dataframe-python\n",
    "train['clean_tweet'] = train['clean_tweet'].replace('', float('NaN'), regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace= True)\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_column = train.pop('label')\n",
    "train.insert(0,'label',first_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Inaasahan na ni Vice President Jejomar Binay n...</td>\n",
       "      <td>inaasahan na ni vice president jejomar binay n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...</td>\n",
       "      <td>mar roxas tang ina tuwid na daan daw  eh sya n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "      <td>salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@rapplerdotcom putangina mo binay TAKBO PA</td>\n",
       "      <td>putangina mo binay takbo pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Binay with selective amnesia, forgetting about...</td>\n",
       "      <td>binay with selective amnesia forgetting about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>It doesn't matter whoever won between Duterte ...</td>\n",
       "      <td>it doesnt matter whoever won between duterte &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Nognog? Pero nognog din ang nag malasakit? Wtf...</td>\n",
       "      <td>nognog pero nognog din ang nag malasakit wtf t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>What Abi Binay said on running for Makati mayo...</td>\n",
       "      <td>what abi binay said on running for makati mayor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Srsly. How can Binay do away with no tax for t...</td>\n",
       "      <td>srsly how can binay do away with no tax for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Sen Grace Poe, puro ka puso. Kaya lugmok bansa...</td>\n",
       "      <td>sen grace poe puro ka puso kaya lugmok bansa n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  Inaasahan na ni Vice President Jejomar Binay n...   \n",
       "1      1  Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA...   \n",
       "2      0  Salamat sa walang sawang suporta ng mga taga m...   \n",
       "3      1         @rapplerdotcom putangina mo binay TAKBO PA   \n",
       "4      0  Binay with selective amnesia, forgetting about...   \n",
       "5      0  It doesn't matter whoever won between Duterte ...   \n",
       "6      1  Nognog? Pero nognog din ang nag malasakit? Wtf...   \n",
       "7      0  What Abi Binay said on running for Makati mayo...   \n",
       "8      1  Srsly. How can Binay do away with no tax for t...   \n",
       "9      1  Sen Grace Poe, puro ka puso. Kaya lugmok bansa...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  inaasahan na ni vice president jejomar binay n...  \n",
       "1  mar roxas tang ina tuwid na daan daw  eh sya n...  \n",
       "2  salamat sa walang sawang suporta ng mga taga m...  \n",
       "3                        putangina mo binay takbo pa  \n",
       "4  binay with selective amnesia forgetting about ...  \n",
       "5  it doesnt matter whoever won between duterte &...  \n",
       "6  nognog pero nognog din ang nag malasakit wtf t...  \n",
       "7    what abi binay said on running for makati mayor  \n",
       "8  srsly how can binay do away with no tax for th...  \n",
       "9  sen grace poe puro ka puso kaya lugmok bansa n...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4747, 3)\n"
     ]
    }
   ],
   "source": [
    "#total data entries for training\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akin', 'aking', 'ako', 'alin', 'am', 'amin', 'aming', 'ang', 'ano', 'anumang', 'apat', 'at', 'atin', 'ating', 'ay', 'bababa', 'bago', 'bakit', 'bawat', 'bilang', 'dahil', 'dalawa', 'dapat', 'din', 'dito', 'doon', 'gagawin', 'gayunman', 'ginagawa', 'ginawa', 'ginawang', 'gumawa', 'gusto', 'habang', 'hanggang', 'hindi', 'huwag', 'iba', 'ibaba', 'ibabaw', 'ibig', 'ikaw', 'ilagay', 'ilalim', 'ilan', 'inyong', 'isa', 'isang', 'itaas', 'ito', 'iyo', 'iyon', 'iyong', 'ka', 'kahit', 'kailangan', 'kailanman', 'kami', 'kanila', 'kanilang', 'kanino', 'kanya', 'kanyang', 'kapag', 'kapwa', 'karamihan', 'katiyakan', 'katulad', 'kaya', 'kaysa', 'ko', 'kong', 'kulang', 'kumuha', 'kung', 'laban', 'lahat', 'lamang', 'likod', 'lima', 'maaari', 'maaaring', 'maging', 'mahusay', 'makita', 'marami', 'marapat', 'masyado', 'may', 'mayroon', 'mga', 'minsan', 'mismo', 'mula', 'muli', 'na', 'nabanggit', 'naging', 'nagkaroon', 'nais', 'nakita', 'namin', 'napaka', 'narito', 'nasaan', 'ng', 'ngayon', 'ni', 'nila', 'nilang', 'nito', 'niya', 'niyang', 'noon', 'o', 'pa', 'paano', 'pababa', 'paggawa', 'pagitan', 'pagkakaroon', 'pagkatapos', 'palabas', 'pamamagitan', 'panahon', 'pangalawa', 'para', 'paraan', 'pareho', 'pataas', 'pero', 'pumunta', 'pumupunta', 'sa', 'saan', 'sabi', 'sabihin', 'sarili', 'sila', 'sino', 'siya', 'tatlo', 'tayo', 'tulad', 'tungkol', 'una', 'walang']\n"
     ]
    }
   ],
   "source": [
    "#remove stopwords\n",
    "import urllib.request, json \n",
    "with urllib.request.urlopen(\"https://raw.githubusercontent.com/stopwords-iso/stopwords-tl/master/stopwords-tl.json\") as url:\n",
    "    stopwords = json.loads(url.read().decode())\n",
    "    print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['content2'] =data['Content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "train['rm_stpwrds'] = train['clean_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>rm_stpwrds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inaasahan na ni vice president jejomar binay n...</td>\n",
       "      <td>inaasahan vice president jejomar binay taong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mar roxas tang ina tuwid na daan daw  eh sya n...</td>\n",
       "      <td>mar roxas tang ina tuwid daan daw eh sya nga d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salamat sa walang sawang suporta ng mga taga m...</td>\n",
       "      <td>salamat sawang suporta taga makati pagbabalik ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putangina mo binay takbo pa</td>\n",
       "      <td>putangina mo binay takbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>binay with selective amnesia forgetting about ...</td>\n",
       "      <td>binay with selective amnesia forgetting about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it doesnt matter whoever won between duterte &amp;...</td>\n",
       "      <td>it doesnt matter whoever won between duterte &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nognog pero nognog din ang nag malasakit wtf t...</td>\n",
       "      <td>nognog nognog nag malasakit wtf tangina mo bin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what abi binay said on running for makati mayor</td>\n",
       "      <td>what abi binay said on running for makati mayor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>srsly how can binay do away with no tax for th...</td>\n",
       "      <td>srsly how can binay do away with no tax for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sen grace poe puro ka puso kaya lugmok bansa n...</td>\n",
       "      <td>sen grace poe puro puso lugmok bansa natin kah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet  \\\n",
       "0  inaasahan na ni vice president jejomar binay n...   \n",
       "1  mar roxas tang ina tuwid na daan daw  eh sya n...   \n",
       "2  salamat sa walang sawang suporta ng mga taga m...   \n",
       "3                        putangina mo binay takbo pa   \n",
       "4  binay with selective amnesia forgetting about ...   \n",
       "5  it doesnt matter whoever won between duterte &...   \n",
       "6  nognog pero nognog din ang nag malasakit wtf t...   \n",
       "7    what abi binay said on running for makati mayor   \n",
       "8  srsly how can binay do away with no tax for th...   \n",
       "9  sen grace poe puro ka puso kaya lugmok bansa n...   \n",
       "\n",
       "                                          rm_stpwrds  \n",
       "0       inaasahan vice president jejomar binay taong  \n",
       "1  mar roxas tang ina tuwid daan daw eh sya nga d...  \n",
       "2  salamat sawang suporta taga makati pagbabalik ...  \n",
       "3                           putangina mo binay takbo  \n",
       "4  binay with selective amnesia forgetting about ...  \n",
       "5  it doesnt matter whoever won between duterte &...  \n",
       "6  nognog nognog nag malasakit wtf tangina mo bin...  \n",
       "7    what abi binay said on running for makati mayor  \n",
       "8  srsly how can binay do away with no tax for th...  \n",
       "9  sen grace poe puro puso lugmok bansa natin kah...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['clean_tweet', 'rm_stpwrds']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [inaasahan, vice, president, jejomar, binay, t...\n",
       "1    [mar, roxas, tang, ina, tuwid, daan, daw, eh, ...\n",
       "2    [salamat, sawang, suporta, taga, makati, pagba...\n",
       "3                        [putangina, mo, binay, takbo]\n",
       "4    [binay, with, selective, amnesia, forgetting, ...\n",
       "Name: tokenize, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization \n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "train['tokenize'] = train['rm_stpwrds'].apply(nltk.tokenize.WhitespaceTokenizer().tokenize) \n",
    "train['tokenize'].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rm_stpwrds</th>\n",
       "      <th>tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inaasahan vice president jejomar binay taong</td>\n",
       "      <td>[inaasahan, vice, president, jejomar, binay, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mar roxas tang ina tuwid daan daw eh sya nga d...</td>\n",
       "      <td>[mar, roxas, tang, ina, tuwid, daan, daw, eh, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salamat sawang suporta taga makati pagbabalik ...</td>\n",
       "      <td>[salamat, sawang, suporta, taga, makati, pagba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putangina mo binay takbo</td>\n",
       "      <td>[putangina, mo, binay, takbo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>binay with selective amnesia forgetting about ...</td>\n",
       "      <td>[binay, with, selective, amnesia, forgetting, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it doesnt matter whoever won between duterte &amp;...</td>\n",
       "      <td>[it, doesnt, matter, whoever, won, between, du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nognog nognog nag malasakit wtf tangina mo bin...</td>\n",
       "      <td>[nognog, nognog, nag, malasakit, wtf, tangina,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what abi binay said on running for makati mayor</td>\n",
       "      <td>[what, abi, binay, said, on, running, for, mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>srsly how can binay do away with no tax for th...</td>\n",
       "      <td>[srsly, how, can, binay, do, away, with, no, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sen grace poe puro puso lugmok bansa natin kah...</td>\n",
       "      <td>[sen, grace, poe, puro, puso, lugmok, bansa, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          rm_stpwrds  \\\n",
       "0       inaasahan vice president jejomar binay taong   \n",
       "1  mar roxas tang ina tuwid daan daw eh sya nga d...   \n",
       "2  salamat sawang suporta taga makati pagbabalik ...   \n",
       "3                           putangina mo binay takbo   \n",
       "4  binay with selective amnesia forgetting about ...   \n",
       "5  it doesnt matter whoever won between duterte &...   \n",
       "6  nognog nognog nag malasakit wtf tangina mo bin...   \n",
       "7    what abi binay said on running for makati mayor   \n",
       "8  srsly how can binay do away with no tax for th...   \n",
       "9  sen grace poe puro puso lugmok bansa natin kah...   \n",
       "\n",
       "                                            tokenize  \n",
       "0  [inaasahan, vice, president, jejomar, binay, t...  \n",
       "1  [mar, roxas, tang, ina, tuwid, daan, daw, eh, ...  \n",
       "2  [salamat, sawang, suporta, taga, makati, pagba...  \n",
       "3                      [putangina, mo, binay, takbo]  \n",
       "4  [binay, with, selective, amnesia, forgetting, ...  \n",
       "5  [it, doesnt, matter, whoever, won, between, du...  \n",
       "6  [nognog, nognog, nag, malasakit, wtf, tangina,...  \n",
       "7  [what, abi, binay, said, on, running, for, mak...  \n",
       "8  [srsly, how, can, binay, do, away, with, no, t...  \n",
       "9  [sen, grace, poe, puro, puso, lugmok, bansa, n...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['rm_stpwrds','tokenize']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenize</th>\n",
       "      <th>lematize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>[nya, demenem, i, binay, a, nyaaa, huhu]</td>\n",
       "      <td>[nya, demenem, i, binay, a, nyaaa, huhu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>[when, i, woke, up, i, was, shocked, that, so,...</td>\n",
       "      <td>[when, i, woke, up, i, wa, shocked, that, so, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>[binay, says, he, doesnt, know, where, friend,...</td>\n",
       "      <td>[binay, say, he, doesnt, know, where, friend, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>[seryoso, tacloban, nga, napala, kay, mar, rox...</td>\n",
       "      <td>[seryoso, tacloban, nga, napala, kay, mar, rox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>[hay, nako, poe, di, mo, talaga, kayang, bangg...</td>\n",
       "      <td>[hay, nako, poe, di, mo, talaga, kayang, bangg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tokenize  \\\n",
       "2446           [nya, demenem, i, binay, a, nyaaa, huhu]   \n",
       "4191  [when, i, woke, up, i, was, shocked, that, so,...   \n",
       "437   [binay, says, he, doesnt, know, where, friend,...   \n",
       "2941  [seryoso, tacloban, nga, napala, kay, mar, rox...   \n",
       "672   [hay, nako, poe, di, mo, talaga, kayang, bangg...   \n",
       "\n",
       "                                               lematize  \n",
       "2446           [nya, demenem, i, binay, a, nyaaa, huhu]  \n",
       "4191  [when, i, woke, up, i, wa, shocked, that, so, ...  \n",
       "437   [binay, say, he, doesnt, know, where, friend, ...  \n",
       "2941  [seryoso, tacloban, nga, napala, kay, mar, rox...  \n",
       "672   [hay, nako, poe, di, mo, talaga, kayang, bangg...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def lema_words(text):\n",
    "  wnl=WordNetLemmatizer()\n",
    "  return[wnl.lemmatize(w) for w in text]\n",
    "\n",
    "train['lematize']=train['tokenize'].apply(lema_words)  \n",
    "train[['tokenize','lematize']].sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceeding to Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the SVM model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m clf \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC()\n\u001b[1;32m----> 3\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Test the model on the testing set\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the SVM model\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with lemmatized words\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['lematize'], train['label'], test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the sentences using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(map(' '.join, X_train))\n",
    "X_test = vectorizer.transform(map(' '.join, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7242105263157895\n"
     ]
    }
   ],
   "source": [
    "# Train the SVM model\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_SET = [\n",
    "    'nakikipag', 'pakikipag',\n",
    "    'pinakama', 'pagpapa',\n",
    "    'pinagka', 'panganga',\n",
    "    'makapag', 'nakapag',\n",
    "    'tagapag', 'makipag',\n",
    "    'nakipag', 'tigapag',\n",
    "    'pakiki', 'magpa',\n",
    "    'napaka', 'pinaka',\n",
    "    'ipinag', 'pagka',\n",
    "    'pinag', 'mapag',\n",
    "    'mapa', 'taga',\n",
    "    'ipag', 'tiga',\n",
    "    'pala', 'pina',\n",
    "    'pang', 'naka',\n",
    "    'nang', 'mang',\n",
    "    'sing',\n",
    "    'ipa', 'pam',\n",
    "    'pan', 'pag',\n",
    "    'tag', 'mai',\n",
    "    'mag', 'nam',\n",
    "    'nag', 'man',\n",
    "    'may', 'ma',\n",
    "    'na', 'ni',\n",
    "    'pa', 'ka',\n",
    "    'um', 'in',\n",
    "    'i',\n",
    "]\n",
    "\n",
    "INFIX_SET = [\n",
    "    'um', 'in',\n",
    "]\n",
    "\n",
    "SUFFIX_SET = [\n",
    "    'syon', 'dor',\n",
    "    'ita', 'han',\n",
    "    'hin', 'ing',\n",
    "    'ang', 'ng',\n",
    "    'an', 'in',\n",
    "    'g',\n",
    "]\n",
    "\n",
    "def tag_lemmatize(word):\n",
    "    prefix = ''\n",
    "    suffix = ''\n",
    "    infix = ''\n",
    "    root = word\n",
    "\n",
    "    # Handle repeated prefixes\n",
    "    for p in PREFIX_SET:\n",
    "        if word.startswith(p) and word[len(p):].startswith(p):\n",
    "            prefix = p\n",
    "            root = word[len(p):]\n",
    "            break\n",
    "        elif word.startswith(p):\n",
    "            prefix = p\n",
    "            root = word[len(p):]\n",
    "            for p2 in PREFIX_SET:\n",
    "                if root.startswith(p2):\n",
    "                    root = root[len(p2):]\n",
    "                    break\n",
    "            break\n",
    "\n",
    "    # Handle repeated suffixes\n",
    "    for s in SUFFIX_SET:\n",
    "        if word.endswith(s) and word[-len(s)-len(word[:-len(s)].rstrip(s)):-len(s)] == s:\n",
    "            suffix = s\n",
    "            root = word[:-len(s)]\n",
    "            break\n",
    "        elif word.endswith(s):\n",
    "            suffix = s\n",
    "            root = word[:-len(s)]\n",
    "            for s2 in SUFFIX_SET:\n",
    "                if root.endswith(s2):\n",
    "                    root = root[:-len(s2)]\n",
    "                    break\n",
    "            break\n",
    "\n",
    "    for i in INFIX_SET:\n",
    "        if i in root:\n",
    "            infix = i\n",
    "            root = root.replace(i, '')\n",
    "            break\n",
    "\n",
    "    # Handle repeated letters\n",
    "    root_len = len(root)\n",
    "    i = 0\n",
    "    while i < root_len - 1:\n",
    "        if root[i] == root[i+1]:\n",
    "            root = root[:i] + root[i+1:]\n",
    "            root_len -= 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naglalaro\n"
     ]
    }
   ],
   "source": [
    "word = 'naglalaro'\n",
    "lemmatized_word = tag_lemmatize(word)\n",
    "print(lemmatized_word) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAGALOG STEMMER\n",
    "\n",
    "PREFIX_SET = [\n",
    "    'nakikipag', 'pakikipag',\n",
    "    'pinakama', 'pagpapa',\n",
    "    'pinagka', 'panganga',\n",
    "    'makapag', 'nakapag',\n",
    "    'tagapag', 'makipag',\n",
    "    'nakipag', 'tigapag',\n",
    "    'pakiki', 'magpa',\n",
    "    'napaka', 'pinaka',\n",
    "    'ipinag', 'pagka',\n",
    "    'pinag', 'mapag',\n",
    "    'mapa', 'taga',\n",
    "    'ipag', 'tiga',\n",
    "    'pala', 'pina',\n",
    "    'pang', 'naka',\n",
    "    'nang', 'mang',\n",
    "    'sing',\n",
    "    'ipa', 'pam',\n",
    "    'pan', 'pag',\n",
    "    'tag', 'mai',\n",
    "    'mag', 'nam',\n",
    "    'nag', 'man',\n",
    "    'may', 'ma',\n",
    "    'na', 'ni',\n",
    "    'pa', 'ka',\n",
    "    'um', 'in',\n",
    "    'i',\n",
    "]\n",
    "\n",
    "INFIX_SET = [\n",
    "    'um', 'in',\n",
    "]\n",
    "\n",
    "SUFFIX_SET = [\n",
    "    'syon', 'dor',\n",
    "    'ita', 'han',\n",
    "    'hin', 'ing',\n",
    "    'ang', 'ng',\n",
    "    'an', 'in',\n",
    "    'g',\n",
    "]\n",
    "\n",
    "def tagalog_stemmer(token):\n",
    "    # remove prefixes\n",
    "    for prefix in PREFIX_SET:\n",
    "        if token.startswith(prefix):\n",
    "            token = token[len(prefix):]\n",
    "            break\n",
    "    # remove infixes\n",
    "    for infix in INFIX_SET:\n",
    "        if infix in token:\n",
    "            token = token.replace(infix, '')\n",
    "            break\n",
    "    # remove suffixes\n",
    "    for suffix in SUFFIX_SET:\n",
    "        if token.endswith(suffix):\n",
    "            token = token[:-len(suffix)]\n",
    "            break\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENGLISH STEMMER\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def english_lemmatizer(token):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "\n",
    "lemmatized_tokens = []\n",
    "for row in train['tokenize']:\n",
    "    lemmatized_row = []\n",
    "    for token in row:\n",
    "        try: \n",
    "            language = detect(token)\n",
    "        except:\n",
    "            continue\n",
    "        if language == 'tl':\n",
    "            lemmatized_token = tagalog_stemmer(token)\n",
    "        elif language == 'en':\n",
    "            lemmatized_token = english_lemmatizer(token)\n",
    "        else:\n",
    "            lemmatized_token = token\n",
    "        lemmatized_row.append(lemmatized_token)\n",
    "    lemmatized_tokens.append(' '.join(lemmatized_row))\n",
    "\n",
    "train['lemmatize_modstem'] = pd.Series(lemmatized_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>lemmatize_modstem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[inaasahan, vice, president, jejomar, binay, t...</td>\n",
       "      <td>inaasahan vice president jejomar bay tao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[mar, roxas, tang, ina, tuwid, daan, daw, eh, ...</td>\n",
       "      <td>mar roxas t ina tuwid daan daw eh sya nga di s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[salamat, sawang, suporta, taga, makati, pagba...</td>\n",
       "      <td>salamat saw suporta  makati babalik bay in makati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[putangina, mo, binay, takbo]</td>\n",
       "      <td>putanga mo bay takbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[binay, with, selective, amnesia, forgetting, ...</td>\n",
       "      <td>bay with selective amnesia forgetting about th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           tokenize   \n",
       "0      0  [inaasahan, vice, president, jejomar, binay, t...  \\\n",
       "1      1  [mar, roxas, tang, ina, tuwid, daan, daw, eh, ...   \n",
       "2      0  [salamat, sawang, suporta, taga, makati, pagba...   \n",
       "3      1                      [putangina, mo, binay, takbo]   \n",
       "4      0  [binay, with, selective, amnesia, forgetting, ...   \n",
       "\n",
       "                                   lemmatize_modstem  \n",
       "0           inaasahan vice president jejomar bay tao  \n",
       "1  mar roxas t ina tuwid daan daw eh sya nga di s...  \n",
       "2  salamat saw suporta  makati babalik bay in makati  \n",
       "3                               putanga mo bay takbo  \n",
       "4  bay with selective amnesia forgetting about th...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['label','tokenize','lemmatize_modstem']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [inaasahan, vice, president, jejomar, bay, tao]\n",
       "1    [mar, roxas, t, ina, tuwid, daan, daw, eh, sya...\n",
       "2    [salamat, saw, suporta, makati, babalik, bay, ...\n",
       "3                            [putanga, mo, bay, takbo]\n",
       "4    [bay, with, selective, amnesia, forgetting, ab...\n",
       "5    [t, doesnt, matter, whoever, won, between, dut...\n",
       "6    [nognog, nognog, lasakit, wtf, tanga, mo, bay,...\n",
       "7    [what, abi, bay, said, on, running, for, makat...\n",
       "8    [srsly, how, can, bay, do, away, with, no, tax...\n",
       "9    [sen, grace, poe, puro, puso, lugmok, bansa, t...\n",
       "Name: lemmatize_modstem, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization \n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "train['lemmatize_modstem'] = train['lemmatize_modstem'].apply(nltk.tokenize.WhitespaceTokenizer().tokenize) \n",
    "train['lemmatize_modstem'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['lemmatize_modstem'], train['label'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the sentences using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(map(' '.join, X_train))\n",
    "X_test = vectorizer.transform(map(' '.join, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7249122807017544\n"
     ]
    }
   ],
   "source": [
    "# Train the SVM model\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
